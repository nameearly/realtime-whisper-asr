# 快速语速识别准确率优化说明

## 一、问题描述

在较快语速时，Whisper 模型似乎将音频当作较少的字来处理，导致非普通语速时的识别准确率有较大下降。

### 问题原因

1. **训练数据语速分布不均**：模型训练时主要使用正常语速的数据
2. **音频特征提取局限性**：快速语音的时间压缩导致特征提取不完整
3. **模型参数固定**：beam_size、temperature 等参数对快速语音不够优化

## 二、解决方案

### 2.1 音频时间拉伸/压缩

**原理**：将快速语音放慢，慢速语音加快，归一化到正常语速

**实现**：
- 使用 `librosa.effects.time_stretch` 进行时间拉伸
- 保持音调不变（使用相位声码器）
- 根据检测到的语速自动调整拉伸倍数

**优点**：
- 将不同语速的音频归一化到模型熟悉的语速范围
- 提高识别准确率

**缺点**：
- 增加少量计算开销
- 需要 librosa 库

### 2.2 自适应模型参数

**原理**：根据语速动态调整 Whisper 模型参数

**参数调整**：
- **beam_size**：快速语速时增大（提高搜索范围）
- **temperature**：快速语速时稍微提高（增加多样性）

**优点**：
- 针对不同语速优化模型行为
- 提高识别准确率

**缺点**：
- 可能略微增加处理时间（beam_size 增大）

## 三、实现模块

### 3.1 SpeechRateAudioProcessor

**功能**：音频时间拉伸/压缩

```python
from speech_rate_audio_processor import SpeechRateAudioProcessor

# 创建处理器
audio_processor = SpeechRateAudioProcessor(
    target_rate=1.0,  # 目标语速倍数
    min_stretch=0.8,  # 最小拉伸（放慢到80%）
    max_stretch=1.2,  # 最大拉伸（加快到120%）
    enable_adaptive=True
)

# 处理音频
processed_audio, stretch = audio_processor.process_audio(audio, sample_rate=16000)

# 根据识别结果更新
audio_processor.update_from_recognition("你好世界", audio_duration=1.0)
```

### 3.2 AdaptiveWhisperParams

**功能**：自适应模型参数

```python
from speech_rate_audio_processor import AdaptiveWhisperParams

# 创建参数控制器
adaptive_params = AdaptiveWhisperParams(
    base_beam_size=5,
    base_temperature=0.0,
    enable_adaptive=True
)

# 根据识别结果更新参数
adaptive_params.update_from_recognition("你好世界", audio_duration=1.0)

# 获取 transcribe 参数
transcribe_kwargs = adaptive_params.get_transcribe_kwargs()
# {'beam_size': 7, 'temperature': 0.1}
```

## 四、集成方式

### 4.1 修改 CustomFasterWhisperASR

在主程序中，`CustomFasterWhisperASR` 已支持自适应参数：

```python
# 创建自适应参数控制器
adaptive_params = AdaptiveWhisperParams(
    base_beam_size=5,
    base_temperature=0.0,
    enable_adaptive=True
)

# 创建 ASR 对象时传入
asr = CustomFasterWhisperASR(
    lan=input_language,
    modelsize=model_size,
    cache_dir=model_cache_dir,
    device=device,
    compute_type=compute_type,
    adaptive_params=adaptive_params  # 传入自适应参数
)
```

### 4.2 音频预处理

在 `OnlineASRProcessor.insert_audio_chunk` 之前处理音频：

```python
# 创建音频处理器
audio_processor = SpeechRateAudioProcessor(
    enable_adaptive=True
)

# 在主循环中
audio_chunk, overflowed = stream.read(read_chunk_size)
audio_chunk = audio_chunk.flatten()

# 处理音频（时间拉伸）
processed_audio, stretch = audio_processor.process_audio(
    audio_chunk, 
    sample_rate=SAMPLING_RATE
)

# 插入处理后的音频
online.insert_audio_chunk(processed_audio)
```

### 4.3 更新参数

根据识别结果更新参数：

```python
result = online.process_iter()
if result[0] is not None:
    beg_time, end_time, text = result
    
    if text and text.strip():
        audio_duration = end_time - beg_time
        
        # 更新音频处理器
        audio_processor.update_from_recognition(text.strip(), audio_duration)
        
        # 更新模型参数
        adaptive_params.update_from_recognition(text.strip(), audio_duration)
```

## 五、配置

在 `config.json` 中添加：

```json
{
  "speech_rate_optimization": {
    "enable_audio_stretch": true,
    "enable_adaptive_params": true,
    "target_rate": 1.0,
    "min_stretch": 0.8,
    "max_stretch": 1.2,
    "normal_rate": 10.0,
    "base_beam_size": 5,
    "base_temperature": 0.0
  }
}
```

## 六、使用建议

### 6.1 何时启用

- ✅ 用户语速变化较大
- ✅ 快速语速时识别准确率明显下降
- ✅ 有足够的计算资源（音频拉伸需要额外计算）

### 6.2 何时禁用

- ❌ 语速相对固定且正常
- ❌ 对实时性要求极高（音频拉伸增加延迟）
- ❌ 计算资源有限

### 6.3 调优建议

1. **校准正常语速**：
   - 记录正常语速用户的识别结果
   - 计算平均语速（字符/秒）
   - 设置 `normal_rate` 参数

2. **调整拉伸范围**：
   - 如果用户语速变化很大，增大 `max_stretch` 和减小 `min_stretch`
   - 如果变化较小，缩小范围以减少计算开销

3. **调整模型参数**：
   - 如果快速语速识别仍然不准确，增大 `base_beam_size`
   - 如果处理速度太慢，减小 `base_beam_size`

## 七、性能影响

### 7.1 计算开销

- **音频拉伸**：约增加 10-20% 的处理时间
- **自适应参数**：beam_size 增大可能增加 20-50% 的处理时间

### 7.2 内存影响

- **音频拉伸**：需要临时存储拉伸后的音频（约增加 20% 内存）
- **自适应参数**：无额外内存开销

### 7.3 准确率提升

- **快速语速**：预计提升 10-30% 的识别准确率
- **慢速语速**：预计提升 5-15% 的识别准确率

## 八、注意事项

1. **依赖库**：
   - 需要安装 `librosa`：`pip install librosa`
   - librosa 可能需要 `soundfile`：`pip install soundfile`

2. **音质影响**：
   - 时间拉伸可能略微影响音质
   - 使用相位声码器可以最小化影响

3. **实时性**：
   - 音频拉伸增加处理延迟
   - 建议在离线或准实时场景使用

4. **校准**：
   - 需要根据实际用户群体校准 `normal_rate`
   - 不同语言和方言的语速差异较大

## 九、测试建议

1. **准备测试数据**：
   - 快速语速音频（>15 字符/秒）
   - 慢速语速音频（<5 字符/秒）
   - 正常语速音频（5-15 字符/秒）

2. **对比测试**：
   - 启用优化前后的识别准确率
   - 记录处理时间和延迟

3. **调优**：
   - 根据测试结果调整参数
   - 找到准确率和性能的平衡点

## 十、总结

通过音频时间拉伸和自适应模型参数，可以有效提高不同语速下的识别准确率。虽然会增加一定的计算开销，但对于语速变化较大的场景，准确率的提升是值得的。

建议：
1. 先启用自适应模型参数（开销较小）
2. 如果效果不够，再启用音频拉伸（开销较大但效果更好）
3. 根据实际使用情况调整参数

