# 语速自适应处理说明

## 一、问题分析

### 1.1 whisper_streaming-main 中的处理

经过代码分析，`whisper_streaming-main` 中**没有专门针对不同语速的处理机制**。

现有的动态调整主要是：
- **静音检测时间调整**：基于说话密集程度（识别结果的时间间隔），而不是语速
- **缓冲区修剪**：基于固定时间阈值（如 15 秒）
- **Local Agreement 策略**：固定 n 值（通常为 2）

### 1.2 语速对识别的影响

不同语速会导致：
- **慢速说话**：
  - 需要更长的静音检测时间，避免过早截断
  - 可以延长处理间隔，减少计算开销
  - 需要更大的缓冲区，保留更多上下文

- **快速说话**：
  - 需要更短的静音检测时间，更快响应
  - 可以缩短处理间隔，提高实时性
  - 可以减小缓冲区，减少延迟

## 二、实现方案

### 2.1 语速检测

**方法**：通过单位时间内的识别文本长度（字符/秒）来估计语速

```python
语速 = 识别文本长度 / 音频时长
```

**分类**：
- **慢速**：< 5 字符/秒
- **正常**：5-15 字符/秒
- **快速**：> 15 字符/秒

### 2.2 自适应参数调整

根据检测到的语速类别，动态调整：

1. **静音检测时间**：
   - 慢速：延长（最多到 1000ms）
   - 快速：缩短（最少到 200ms）
   - 正常：逐渐回归到初始值（500ms）

2. **处理间隔**：
   - 慢速：延长（最多到 2.0 秒）
   - 快速：缩短（最少到 0.5 秒）
   - 正常：逐渐回归到初始值（1.0 秒）

### 2.3 实现模块

创建了 `speech_rate_adaptive.py` 模块，包含：

1. **SpeechRateDetector**：语速检测器
   - 记录识别结果
   - 计算语速指标
   - 分类语速

2. **AdaptiveParameterController**：自适应参数控制器
   - 根据语速调整参数
   - 平滑过渡（避免频繁变化）
   - 记录调整历史

3. **SpeechRateAdaptiveProcessor**：语速自适应处理器
   - 包装 OnlineASRProcessor
   - 自动应用自适应参数
   - 提供状态查询接口

## 三、使用方法

### 3.1 基本使用

```python
from speech_rate_adaptive import SpeechRateAdaptiveProcessor

# 创建自适应处理器
adaptive_processor = SpeechRateAdaptiveProcessor(
    online_processor=online,  # OnlineASRProcessor 对象
    vad_processor=vac,  # VAD 处理器（如果有）
    initial_silence_ms=500,
    initial_chunk_duration=1.0
)

# 处理识别结果
result = online.process_iter()
if result[0] is not None:
    # 通过自适应处理器处理（会自动更新参数）
    result = adaptive_processor.process_recognition_result(result)
    
    # 获取自适应处理间隔
    chunk_duration = adaptive_processor.get_adaptive_chunk_duration()
    
    # 获取语速统计
    rate_stats = adaptive_processor.get_rate_stats()
    print(f"语速: {rate_stats['avg_rate']:.1f} 字符/秒 ({rate_stats['category']})")
```

### 3.2 配置

在 `config.json` 中添加：

```json
{
  "speech_rate_adaptive": {
    "enable": true,
    "initial_silence_ms": 500,
    "min_silence_ms": 200,
    "max_silence_ms": 1000,
    "initial_chunk_duration": 1.0,
    "min_chunk_duration": 0.5,
    "max_chunk_duration": 2.0,
    "rate_threshold_slow": 5.0,
    "rate_threshold_fast": 15.0
  }
}
```

### 3.3 集成到主程序

在主程序的 `record_session` 函数中：

```python
# 创建自适应处理器
if SPEECH_RATE_ADAPTIVE_AVAILABLE:
    from speech_rate_adaptive import SpeechRateAdaptiveProcessor
    adaptive_processor = SpeechRateAdaptiveProcessor(
        online_processor=online,
        vad_processor=online if hasattr(online, 'set_silence_duration') else None,
        initial_silence_ms=500,
        initial_chunk_duration=1.0
    )

# 在主循环中
result = online.process_iter()
if result[0] is not None:
    # 通过自适应处理器处理
    if adaptive_processor:
        result = adaptive_processor.process_recognition_result(result)
        # 显示语速信息
        rate_stats = adaptive_processor.get_rate_stats()
        if perf_display:
            perf_display.display_info(
                f"语速: {rate_stats['avg_rate']:.1f} 字符/秒 ({rate_stats['category']})"
            )
```

## 四、GitHub 参考项目

虽然 GitHub 上没有找到专门针对实时 ASR 语速自适应的项目，但可以参考以下思路：

### 4.1 相关技术

1. **自适应 VAD**：
   - 根据语音活动动态调整静音检测时间
   - 参考：Silero VAD 的自适应阈值

2. **动态缓冲区管理**：
   - 根据处理速度调整缓冲区大小
   - 参考：whisper-streaming 的 buffer_trimming

3. **自适应采样**：
   - 根据语速调整采样策略
   - 参考：音频信号处理中的自适应采样

### 4.2 类似项目

虽然没有完全匹配的项目，但可以参考：

1. **pyvideotrans6**：
   - 提供语速调整功能（-90 到 +90）
   - 可以了解语速检测和调整的思路

2. **Whisper 优化实践**：
   - 模型压缩和加速技术
   - 有助于在不同语速下保持性能

## 五、优势

1. **自适应**：根据实际语速自动调整，无需手动配置
2. **平滑过渡**：参数变化平滑，避免突然变化
3. **可配置**：所有阈值和范围都可以配置
4. **向后兼容**：可选功能，不影响现有代码

## 六、注意事项

1. **语速检测准确性**：
   - 依赖识别结果的准确性
   - 可能需要多个样本才能准确估计

2. **参数调整频率**：
   - 避免过于频繁的调整
   - 使用平滑过渡机制

3. **边界情况**：
   - 处理极端语速（极快或极慢）
   - 处理识别错误导致的异常值

## 七、未来改进

1. **更精确的语速检测**：
   - 使用音频特征（如基频、能量）辅助检测
   - 结合文本特征（词数、音节数）

2. **多维度自适应**：
   - 同时调整多个参数（缓冲区、Local Agreement n 值等）
   - 考虑说话风格（停顿频率、语调等）

3. **学习机制**：
   - 记录用户习惯
   - 个性化参数调整

