#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸€é”®å®æ—¶è¯†åˆ«éº¦å…‹é£
ç›´æ¥è¿è¡Œæ­¤è„šæœ¬å³å¯å¼€å§‹å®æ—¶è¯­éŸ³è¯†åˆ«

é…ç½®è¯´æ˜ï¼š
- æ‰€æœ‰é…ç½®é€šè¿‡ config.json æ–‡ä»¶ç®¡ç†ï¼Œç¨‹åºå¯åŠ¨æ—¶è‡ªåŠ¨åŠ è½½
- é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶
- æ”¯æŒè¯­è¨€ç‰¹å®šé…ç½®ï¼ˆä¸­æ–‡ã€è‹±æ–‡ç­‰ï¼‰ï¼Œè‡ªåŠ¨æ ¹æ®è¯†åˆ«è¯­è¨€é€‰æ‹©å¯¹åº”é…ç½®
- ä¸»è¦é…ç½®é¡¹ï¼š
  * è¯†åˆ«è¯­è¨€ï¼šç¨‹åºå¯åŠ¨æ—¶é€‰æ‹©ï¼ˆæ”¯æŒè¿è¡Œæ—¶åˆ‡æ¢ï¼‰
  * æ¨¡å‹å¤§å°ï¼šç¨‹åºå¯åŠ¨æ—¶é€‰æ‹©
  * è·³å¥æ£€æµ‹ï¼šconfig.json ä¸­çš„ skip_detector é…ç½®
  * è¯­é€Ÿè‡ªé€‚åº”ï¼šconfig.json ä¸­çš„ speech_rate_adaptive é…ç½®
  * ASRä¼˜åŒ–ï¼šconfig.json ä¸­çš„ asr_optimization é…ç½®
  * äººå£°åˆ†ç¦»ï¼šconfig.json ä¸­çš„ vocal_separation é…ç½®
  * éŸ³é¢‘å»é‡ï¼šconfig.json ä¸­çš„ audio_deduplication é…ç½®

è¯¦ç»†é…ç½®è¯´æ˜è¯·å‚è€ƒ config.json æ–‡ä»¶ä¸­çš„æ³¨é‡Šã€‚
"""

import sys
import os
import time
import logging
from datetime import datetime
import queue
import threading

# å¯¼å…¥æ–°æ¨¡å—
try:
    from audio_device_protector import AudioDeviceProtector
    DEVICE_PROTECTOR_AVAILABLE = True
except ImportError:
    DEVICE_PROTECTOR_AVAILABLE = False

try:
    from improved_skip_detector import ImprovedSkipDetector
    SKIP_DETECTOR_AVAILABLE = True
except ImportError:
    SKIP_DETECTOR_AVAILABLE = False

try:
    from audio_deduplicator import AudioDeduplicator
    AUDIO_DEDUPLICATOR_AVAILABLE = True
except ImportError:
    AUDIO_DEDUPLICATOR_AVAILABLE = False

try:
    from config_manager import ConfigManager
    CONFIG_MANAGER_AVAILABLE = True
except ImportError:
    CONFIG_MANAGER_AVAILABLE = False

try:
    from performance_display import PerformanceDisplay
    PERFORMANCE_DISPLAY_AVAILABLE = True
except ImportError:
    PERFORMANCE_DISPLAY_AVAILABLE = False

try:
    from vocal_separation import create_separator
    VOCAL_SEPARATION_AVAILABLE = True
except ImportError:
    VOCAL_SEPARATION_AVAILABLE = False

# å¯¼å…¥ASRç»„ä»¶
try:
    from asr_components import DynamicVADIterator, DynamicVACOnlineASRProcessor, create_custom_faster_whisper_asr
    ASR_COMPONENTS_AVAILABLE = True
except ImportError:
    ASR_COMPONENTS_AVAILABLE = False
    print("âš  ASRç»„ä»¶æ¨¡å—ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨å†…ç½®ç±»")

# æ·»åŠ  whisper_streaming è·¯å¾„
whisper_path = os.path.join(os.path.dirname(__file__), 'whisper_streaming-main', 'whisper_streaming-main')
if os.path.exists(whisper_path):
    sys.path.insert(0, whisper_path)
else:
    print(f"é”™è¯¯: æ‰¾ä¸åˆ° whisper_streaming ç›®å½•: {whisper_path}")
    sys.exit(1)

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–"""
    missing = []
    try:
        import numpy as np
    except ImportError:
        missing.append("numpy")
    
    try:
        import sounddevice as sd
    except ImportError:
        missing.append("sounddevice")
    
    try:
        from faster_whisper import WhisperModel
    except ImportError:
        missing.append("faster-whisper")
    
    # requests ç”¨äºè°ƒç”¨ç¿»è¯‘ APIï¼ˆå¯é€‰ï¼‰
    try:
        import requests
    except ImportError:
        pass  # requests æ˜¯å¯é€‰çš„ï¼Œåªåœ¨å¯ç”¨ç¿»è¯‘æ—¶éœ€è¦
    
    if missing:
        print("ç¼ºå°‘ä»¥ä¸‹ä¾èµ–ï¼Œè¯·å…ˆå®‰è£…ï¼š")
        print(f"pip install {' '.join(missing)}")
        return False
    return True

def detect_hardware():
    """æ£€æµ‹ç¡¬ä»¶é…ç½®"""
    import psutil
    import os
    
    hardware_info = {
        'cpu_cores': psutil.cpu_count(logical=False),  # ç‰©ç†æ ¸å¿ƒæ•°
        'cpu_threads': psutil.cpu_count(logical=True),  # é€»è¾‘æ ¸å¿ƒæ•°
        'ram_gb': round(psutil.virtual_memory().total / (1024**3), 1),  # å†…å­˜GB
        'gpu_available': False,
        'gpu_memory_gb': 0,
        'gpu_memory_free_gb': 0,
        'gpu_name': None,
        'gpu_count': 0,
        'cuda_version': None,
        'gpu_devices': []
    }
    
    # æ£€æµ‹ NVIDIA GPU
    try:
        import subprocess
        # è·å– GPU ä¿¡æ¯
        result = subprocess.run(['nvidia-smi', '--query-gpu=index,name,memory.total,memory.free,driver_version', 
                                '--format=csv,noheader,nounits'], 
                              capture_output=True, text=True, timeout=5)
        if result.returncode == 0 and result.stdout.strip():
            lines = result.stdout.strip().split('\n')
            hardware_info['gpu_count'] = len(lines)
            if lines:
                # ä½¿ç”¨ç¬¬ä¸€ä¸ª GPU
                gpu_info = lines[0].split(',')
                hardware_info['gpu_available'] = True
                hardware_info['gpu_name'] = gpu_info[1].strip()
                hardware_info['gpu_memory_gb'] = round(int(gpu_info[2].strip()) / 1024, 1)
                hardware_info['gpu_memory_free_gb'] = round(int(gpu_info[3].strip()) / 1024, 1)
                
                # æ”¶é›†æ‰€æœ‰ GPU ä¿¡æ¯
                for line in lines:
                    parts = line.split(',')
                    if len(parts) >= 4:
                        hardware_info['gpu_devices'].append({
                            'index': int(parts[0].strip()),
                            'name': parts[1].strip(),
                            'memory_total_gb': round(int(parts[2].strip()) / 1024, 1),
                            'memory_free_gb': round(int(parts[3].strip()) / 1024, 1)
                        })
        
        # æ£€æµ‹ CUDA ç‰ˆæœ¬
        try:
            cuda_result = subprocess.run(['nvcc', '--version'], 
                                       capture_output=True, text=True, timeout=3)
            if cuda_result.returncode == 0:
                for line in cuda_result.stdout.split('\n'):
                    if 'release' in line.lower():
                        import re
                        match = re.search(r'release\s+(\d+\.\d+)', line, re.IGNORECASE)
                        if match:
                            hardware_info['cuda_version'] = match.group(1)
        except:
            pass
    except:
        pass  # nvidia-smi ä¸å¯ç”¨æˆ–æ²¡æœ‰GPU
    
    return hardware_info

def optimize_low_level_params(hardware_info, use_gpu, model_size):
    """æ ¹æ® GPU æƒ…å†µä¼˜åŒ–åº•å±‚å‚æ•°"""
    params = {
        'num_workers': 1,  # CPU çº¿ç¨‹æ•°ï¼ˆå®æ—¶åœºæ™¯é€šå¸¸ç”¨ 1ï¼‰
        'device_index': 0,  # GPU è®¾å¤‡ç´¢å¼•
        'cpu_threads': None,  # CPU çº¿ç¨‹æ•°ï¼ˆç”¨äº CPU æ¨¡å¼ï¼‰
        'enable_memory_efficient': False,  # å†…å­˜ä¼˜åŒ–
        'optimization_level': None,  # ä¼˜åŒ–çº§åˆ«
    }
    
    if use_gpu and hardware_info['gpu_available']:
        gpu_free = hardware_info['gpu_memory_free_gb']
        
        # é€‰æ‹© GPU è®¾å¤‡ï¼ˆå¦‚æœæœ‰å¤šä¸ªï¼Œé€‰æ‹©æ˜¾å­˜æœ€å¤šçš„ï¼‰
        if hardware_info['gpu_count'] > 1:
            best_gpu = max(hardware_info['gpu_devices'], 
                          key=lambda x: x['memory_free_gb'])
            params['device_index'] = best_gpu['index']
            params['reason'] = f"æ£€æµ‹åˆ° {hardware_info['gpu_count']} ä¸ª GPUï¼Œé€‰æ‹© GPU {best_gpu['index']} ({best_gpu['name']})"
        else:
            params['device_index'] = 0
        
        # æ ¹æ®æ˜¾å­˜æƒ…å†µè°ƒæ•´ä¼˜åŒ–
        if gpu_free < 2:
            params['enable_memory_efficient'] = True
            params['optimization_level'] = 'aggressive'
            params['reason'] = (params.get('reason', '') + 
                              f"\n  - æ˜¾å­˜ç´§å¼  ({gpu_free:.1f}GB å¯ç”¨)ï¼Œå¯ç”¨å†…å­˜ä¼˜åŒ–")
        elif gpu_free < 4:
            params['enable_memory_efficient'] = True
            params['optimization_level'] = 'moderate'
            params['reason'] = (params.get('reason', '') + 
                              f"\n  - æ˜¾å­˜ä¸­ç­‰ ({gpu_free:.1f}GB å¯ç”¨)ï¼Œå¯ç”¨é€‚åº¦å†…å­˜ä¼˜åŒ–")
        else:
            params['reason'] = (params.get('reason', '') + 
                              f"\n  - æ˜¾å­˜å……è¶³ ({gpu_free:.1f}GB å¯ç”¨)ï¼Œä½¿ç”¨æ ‡å‡†é…ç½®")
        
        # æ ¹æ®æ¨¡å‹å¤§å°è°ƒæ•´
        if model_size in ['large-v2', 'large-v3', 'large']:
            params['enable_memory_efficient'] = True
            params['reason'] = (params.get('reason', '') + 
                              f"\n  - å¤§æ¨¡å‹ ({model_size})ï¼Œå¯ç”¨å†…å­˜ä¼˜åŒ–")
    else:
        # CPU æ¨¡å¼ä¼˜åŒ–
        cpu_threads = hardware_info['cpu_threads']
        # å®æ—¶åœºæ™¯ä¸‹ï¼Œä½¿ç”¨è¾ƒå°‘çš„çº¿ç¨‹é¿å…å»¶è¿Ÿ
        # ä½†å¯ä»¥æ ¹æ®æ ¸å¿ƒæ•°é€‚å½“è°ƒæ•´
        if cpu_threads >= 16:
            params['cpu_threads'] = min(8, cpu_threads // 2)  # æœ€å¤š 8 çº¿ç¨‹
            params['reason'] = f"CPU {cpu_threads} çº¿ç¨‹ï¼Œä½¿ç”¨ {params['cpu_threads']} ä¸ªçº¿ç¨‹"
        elif cpu_threads >= 8:
            params['cpu_threads'] = min(4, cpu_threads // 2)
            params['reason'] = f"CPU {cpu_threads} çº¿ç¨‹ï¼Œä½¿ç”¨ {params['cpu_threads']} ä¸ªçº¿ç¨‹"
        else:
            params['cpu_threads'] = cpu_threads
            params['reason'] = f"CPU {cpu_threads} çº¿ç¨‹ï¼Œä½¿ç”¨å…¨éƒ¨çº¿ç¨‹"
    
    return params

def recommend_config(hardware_info, use_gpu):
    """
    æ ¹æ®ç¡¬ä»¶é…ç½®æ¨èè¿è¡Œå‚æ•°ï¼ˆåŸºäºçœŸå®æ€§èƒ½æ•°æ®ï¼‰
    
    å‚è€ƒä¿¡æ¯ï¼š
    - tiny: ~39Må‚æ•°, 75MB, GPUçº¦0.5GB, CPUå®æ—¶æ€§è¾ƒå¥½
    - base: ~74Må‚æ•°, 142MB, GPUçº¦1GB, CPUå®æ—¶æ€§ä¸€èˆ¬
    - small: ~244Må‚æ•°, 466MB, GPUçº¦2GB, CPUå®æ—¶æ€§è¾ƒå·®
    - medium: ~769Må‚æ•°, 1.4GB, GPUçº¦5GB, CPUä¸é€‚åˆå®æ—¶
    - large-v2/v3: ~1550Må‚æ•°, 3GB, GPUçº¦10GB, CPUä¸é€‚åˆå®æ—¶
    """
    recommendations = {
        'device': 'cuda' if use_gpu and hardware_info['gpu_available'] else 'cpu',
        'compute_type': None,
        'model_size': None,
        'reason': []
    }
    
    if use_gpu and hardware_info['gpu_available']:
        # GPU æ¨¡å¼ - åŸºäºçœŸå®æ˜¾å­˜éœ€æ±‚
        gpu_memory = hardware_info['gpu_memory_gb']
        gpu_free = hardware_info['gpu_memory_free_gb']
        
        # large-v2/v3 éœ€è¦çº¦ 10GB æ˜¾å­˜ï¼ˆfloat16ï¼‰
        if gpu_memory >= 10 and gpu_free >= 8:
            recommendations['model_size'] = 'large-v2'
            recommendations['compute_type'] = 'float16'
            recommendations['reason'].append(f"GPU æ˜¾å­˜ {gpu_memory}GB (å¯ç”¨ {gpu_free:.1f}GB) å……è¶³ï¼Œå¯è¿è¡Œ large-v2")
            recommendations['reason'].append("æ³¨æ„ï¼šlarge æ¨¡å‹åœ¨å®æ—¶åœºæ™¯ä¸‹å»¶è¿Ÿè¾ƒé«˜ï¼ˆ3-5ç§’ï¼‰ï¼Œå»ºè®® medium")
        # medium éœ€è¦çº¦ 5GB æ˜¾å­˜
        elif gpu_memory >= 6 and gpu_free >= 4:
            recommendations['model_size'] = 'medium'
            recommendations['compute_type'] = 'float16'
            recommendations['reason'].append(f"GPU æ˜¾å­˜ {gpu_memory}GB (å¯ç”¨ {gpu_free:.1f}GB)ï¼Œæ¨è medium æ¨¡å‹")
            recommendations['reason'].append("medium æ¨¡å‹ï¼šå‡†ç¡®åº¦é«˜ï¼Œå®æ—¶å»¶è¿Ÿçº¦ 1-2 ç§’ï¼ˆæ¨èï¼‰")
        # small éœ€è¦çº¦ 2GB æ˜¾å­˜
        elif gpu_memory >= 4 and gpu_free >= 2.5:
            recommendations['model_size'] = 'small'
            recommendations['compute_type'] = 'float16'
            recommendations['reason'].append(f"GPU æ˜¾å­˜ {gpu_memory}GB (å¯ç”¨ {gpu_free:.1f}GB)ï¼Œæ¨è small æ¨¡å‹")
            recommendations['reason'].append("small æ¨¡å‹ï¼šå¹³è¡¡å‡†ç¡®åº¦å’Œé€Ÿåº¦ï¼Œå®æ—¶å»¶è¿Ÿçº¦ 0.5-1 ç§’")
        # base éœ€è¦çº¦ 1GB æ˜¾å­˜
        elif gpu_memory >= 2 and gpu_free >= 1.5:
            recommendations['model_size'] = 'base'
            recommendations['compute_type'] = 'float16'
            recommendations['reason'].append(f"GPU æ˜¾å­˜ {gpu_memory}GB (å¯ç”¨ {gpu_free:.1f}GB)ï¼Œæ¨è base æ¨¡å‹")
            recommendations['reason'].append("base æ¨¡å‹ï¼šé€Ÿåº¦å¿«ï¼Œå®æ—¶å»¶è¿Ÿçº¦ 0.3-0.5 ç§’ï¼Œå‡†ç¡®åº¦ä¸­ç­‰")
        else:
            # æ˜¾å­˜ä¸è¶³ï¼Œä½¿ç”¨ int8 é‡åŒ–
            recommendations['model_size'] = 'base'
            recommendations['compute_type'] = 'int8_float16'
            recommendations['reason'].append(f"GPU æ˜¾å­˜ {gpu_memory}GB (å¯ç”¨ {gpu_free:.1f}GB) è¾ƒå°ï¼Œä½¿ç”¨ base æ¨¡å‹ï¼ˆint8 é‡åŒ–ï¼‰")
    else:
        # CPU æ¨¡å¼ - åŸºäºçœŸå®æ€§èƒ½æ•°æ®
        cpu_cores = hardware_info['cpu_cores']
        cpu_threads = hardware_info['cpu_threads']
        ram_gb = hardware_info['ram_gb']
        
        # CPU å®æ—¶åœºæ™¯ï¼šåªæœ‰ tiny å’Œ base é€‚åˆï¼Œsmall ä»¥ä¸Šå»¶è¿Ÿå¤ªé«˜
        if cpu_threads >= 16 and ram_gb >= 16:
            # é«˜æ€§èƒ½ CPUï¼šå¯ä»¥å°è¯• smallï¼Œä½†æ¨è base
            recommendations['model_size'] = 'base'
            recommendations['compute_type'] = 'int8'
            recommendations['reason'].append(f"CPU {cpu_cores}æ ¸/{cpu_threads}çº¿ç¨‹ + {ram_gb}GB å†…å­˜")
            recommendations['reason'].append("CPU æ¨¡å¼ï¼šæ¨è base æ¨¡å‹ï¼ˆint8ï¼‰ï¼Œå®æ—¶å»¶è¿Ÿçº¦ 1-2 ç§’")
            recommendations['reason'].append("æ³¨æ„ï¼šsmall ä»¥ä¸Šæ¨¡å‹åœ¨ CPU ä¸Šå»¶è¿Ÿè¿‡é«˜ï¼ˆ>3ç§’ï¼‰ï¼Œä¸é€‚åˆå®æ—¶")
        elif cpu_threads >= 8 and ram_gb >= 8:
            recommendations['model_size'] = 'base'
            recommendations['compute_type'] = 'int8'
            recommendations['reason'].append(f"CPU {cpu_cores}æ ¸/{cpu_threads}çº¿ç¨‹ + {ram_gb}GB å†…å­˜ï¼Œæ¨è base æ¨¡å‹")
        else:
            recommendations['model_size'] = 'tiny'
            recommendations['compute_type'] = 'int8'
            recommendations['reason'].append(f"CPU {cpu_cores}æ ¸/{cpu_threads}çº¿ç¨‹ + {ram_gb}GB å†…å­˜ï¼Œæ¨è tiny æ¨¡å‹")
            recommendations['reason'].append("tiny æ¨¡å‹ï¼šCPU ä¸Šé€Ÿåº¦æœ€å¿«ï¼Œå®æ—¶å»¶è¿Ÿçº¦ 0.5-1 ç§’")
    
    return recommendations

def recommend_demucs_config(hardware_info, use_gpu, whisper_model_size=None):
    """
    æ ¹æ®GPUæ˜¾å­˜æ¨èDemucsæ¨¡å‹é…ç½®ï¼Œè€ƒè™‘Whisperæ¨¡å‹çš„æ˜¾å­˜å ç”¨
    
    æ˜¾å­˜éœ€æ±‚å‚è€ƒï¼ˆåŸºäºå®é™…æµ‹è¯•ï¼‰ï¼š
    - Whisperæ¨¡å‹æ˜¾å­˜å ç”¨ï¼ˆfloat16ï¼‰ï¼š
      * tiny: ~0.5GB
      * base: ~1GB
      * small: ~2GB
      * medium: ~5GB
      * large-v2/v3: ~10GB
    
    - Demucsæ¨¡å‹æ˜¾å­˜å ç”¨ï¼ˆæ¨ç†æ—¶ï¼‰ï¼š
      * htdemucs: ~1.5-2GBï¼ˆè½»é‡çº§ï¼Œæ¨èï¼‰
      * htdemucs_ft: ~3-4GBï¼ˆæ›´é«˜è´¨é‡ä½†æ›´æ…¢ï¼‰
      * htdemucs_6s: ~2-2.5GBï¼ˆ6ç§éŸ³æºåˆ†ç¦»ï¼‰
      * hdemucs_mmi: ~2.5-3GBï¼ˆæ··åˆæ¨¡å‹ï¼‰
      * mdx: ~2-3GBï¼ˆé«˜è´¨é‡ï¼Œè¾ƒæ…¢ï¼‰
      * mdx_extra: ~3-4GBï¼ˆæœ€é«˜è´¨é‡ï¼Œæœ€æ…¢ï¼‰
    
    æ³¨æ„ï¼šå®é™…æ˜¾å­˜å ç”¨è¿˜å–å†³äºéŸ³é¢‘é•¿åº¦å’Œæ‰¹å¤„ç†å¤§å°
    """
    recommendations = {
        'demucs_model': None,
        'enable': False,
        'reason': [],
        'warnings': []
    }
    
    if not use_gpu or not hardware_info['gpu_available']:
        # CPUæ¨¡å¼ï¼šä¸æ¨èä½¿ç”¨Demucsï¼ˆå¤ªæ…¢ï¼‰
        recommendations['enable'] = False
        recommendations['reason'].append("CPUæ¨¡å¼ï¼šä¸æ¨èä½¿ç”¨Demucsï¼ˆå¤„ç†é€Ÿåº¦å¤ªæ…¢ï¼Œä¸é€‚åˆå®æ—¶ï¼‰")
        recommendations['reason'].append("å»ºè®®ï¼šä½¿ç”¨filteræ–¹æ³•ï¼ˆé¢‘åŸŸæ»¤æ³¢ï¼‰æˆ–å…³é—­äººå£°åˆ†ç¦»")
        return recommendations
    
    gpu_memory = hardware_info['gpu_memory_gb']
    gpu_free = hardware_info['gpu_memory_free_gb']
    
    # ä¼°ç®—Whisperæ¨¡å‹çš„æ˜¾å­˜å ç”¨
    whisper_vram = 0
    if whisper_model_size:
        whisper_vram_map = {
            'tiny': 0.5,
            'base': 1.0,
            'small': 2.0,
            'medium': 5.0,
            'large-v1': 10.0,
            'large-v2': 10.0,
            'large-v3': 10.0,
            'large': 10.0
        }
        whisper_vram = whisper_vram_map.get(whisper_model_size.lower(), 2.0)
    
    # è®¡ç®—å¯ç”¨äºDemucsçš„æ˜¾å­˜ï¼ˆé¢„ç•™1GBç»™ç³»ç»Ÿå’Œå…¶ä»–å¼€é”€ï¼‰
    available_for_demucs = gpu_free - whisper_vram - 1.0
    
    recommendations['reason'].append(f"GPUæ€»æ˜¾å­˜: {gpu_memory}GB")
    recommendations['reason'].append(f"å½“å‰å¯ç”¨æ˜¾å­˜: {gpu_free:.1f}GB")
    if whisper_model_size:
        recommendations['reason'].append(f"Whisperæ¨¡å‹ ({whisper_model_size}) é¢„è®¡å ç”¨: ~{whisper_vram}GB")
        recommendations['reason'].append(f"å¯ç”¨äºDemucsçš„æ˜¾å­˜: ~{available_for_demucs:.1f}GB")
    
    # æ ¹æ®å¯ç”¨æ˜¾å­˜æ¨èDemucsæ¨¡å‹
    if available_for_demucs >= 3.5:
        # æ˜¾å­˜å……è¶³ï¼šå¯ä»¥ä½¿ç”¨é«˜è´¨é‡æ¨¡å‹
        recommendations['demucs_model'] = 'htdemucs_ft'
        recommendations['enable'] = True
        recommendations['reason'].append("âœ“ æ¨è: htdemucs_ftï¼ˆæ›´é«˜è´¨é‡ï¼Œæ˜¾å­˜å……è¶³ï¼‰")
        recommendations['reason'].append("  æ˜¾å­˜å ç”¨: ~3-4GBï¼Œåˆ†ç¦»è´¨é‡æœ€é«˜")
    elif available_for_demucs >= 2.5:
        # æ˜¾å­˜ä¸­ç­‰ï¼šä½¿ç”¨æ ‡å‡†æ¨¡å‹
        recommendations['demucs_model'] = 'htdemucs'
        recommendations['enable'] = True
        recommendations['reason'].append("âœ“ æ¨è: htdemucsï¼ˆè½»é‡çº§ï¼Œå¹³è¡¡è´¨é‡å’Œé€Ÿåº¦ï¼‰")
        recommendations['reason'].append("  æ˜¾å­˜å ç”¨: ~1.5-2GBï¼Œé€‚åˆå®æ—¶å¤„ç†")
    elif available_for_demucs >= 1.5:
        # æ˜¾å­˜ç´§å¼ ï¼šä½¿ç”¨è½»é‡çº§æ¨¡å‹
        recommendations['demucs_model'] = 'htdemucs'
        recommendations['enable'] = True
        recommendations['warnings'].append("âš  æ˜¾å­˜ç´§å¼ ï¼Œå»ºè®®ä½¿ç”¨ htdemucsï¼ˆæœ€è½»é‡çº§ï¼‰")
        recommendations['warnings'].append("  å¦‚æœå‡ºç°OOMé”™è¯¯ï¼Œè€ƒè™‘ï¼š")
        recommendations['warnings'].append("  1. é™ä½Whisperæ¨¡å‹å¤§å°")
        recommendations['warnings'].append("  2. ä½¿ç”¨filteræ–¹æ³•æ›¿ä»£Demucs")
        recommendations['warnings'].append("  3. å…³é—­äººå£°åˆ†ç¦»")
    else:
        # æ˜¾å­˜ä¸è¶³ï¼šä¸æ¨èä½¿ç”¨Demucs
        recommendations['enable'] = False
        recommendations['warnings'].append("âŒ æ˜¾å­˜ä¸è¶³ï¼Œæ— æ³•åŒæ—¶è¿è¡ŒWhisperå’ŒDemucs")
        recommendations['warnings'].append(f"  éœ€è¦è‡³å°‘ {whisper_vram + 2.5:.1f}GB æ˜¾å­˜ï¼ˆWhisper + Demucs + ç³»ç»Ÿå¼€é”€ï¼‰")
        recommendations['warnings'].append("  å»ºè®®ï¼š")
        recommendations['warnings'].append("  1. ä½¿ç”¨filteræ–¹æ³•ï¼ˆé¢‘åŸŸæ»¤æ³¢ï¼Œæ— éœ€é¢å¤–æ˜¾å­˜ï¼‰")
        recommendations['warnings'].append("  2. é™ä½Whisperæ¨¡å‹å¤§å°")
        recommendations['warnings'].append("  3. å…³é—­äººå£°åˆ†ç¦»")
    
    return recommendations

# æ³¨æ„ï¼šæ—§çš„APIè°ƒç”¨ç›¸å…³ä»£ç å·²ç§»é™¤ï¼Œç¿»è¯‘åŠŸèƒ½å·²è¿ç§»åˆ° translation_manager.py æ¨¡å—

# ========== å¼‚æ­¥è¾“å‡ºæœºåˆ¶ï¼ˆé¿å…è¾“å‡ºé˜»å¡ä¸»å¾ªç¯ï¼‰ ==========
class AsyncOutput:
    """å¼‚æ­¥è¾“å‡ºç±»ï¼Œä½¿ç”¨é˜Ÿåˆ—å’Œåå°çº¿ç¨‹é¿å…è¾“å‡ºæ“ä½œé˜»å¡ä¸»å¾ªç¯"""
    
    def __init__(self):
        self.output_queue = queue.Queue(maxsize=100)  # é™åˆ¶é˜Ÿåˆ—å¤§å°ï¼Œé¿å…å†…å­˜æ— é™å¢é•¿
        self.running = False
        self.thread = None
    
    def start(self):
        """å¯åŠ¨åå°è¾“å‡ºçº¿ç¨‹"""
        if self.running:
            return
        self.running = True
        self.thread = threading.Thread(target=self._output_worker, daemon=True)
        self.thread.start()
    
    def stop(self):
        """åœæ­¢åå°è¾“å‡ºçº¿ç¨‹"""
        self.running = False
        # æ·»åŠ åœæ­¢æ ‡è®°
        try:
            self.output_queue.put_nowait(("__STOP__", None))
        except queue.Full:
            pass
        if self.thread:
            self.thread.join(timeout=1.0)
    
    def _output_worker(self):
        """åå°è¾“å‡ºå·¥ä½œçº¿ç¨‹"""
        while self.running:
            try:
                # ä½¿ç”¨è¶…æ—¶é¿å…æ— é™ç­‰å¾…
                item = self.output_queue.get(timeout=0.1)
                if item[0] == "__STOP__":
                    break
                output_type, content = item
                
                if output_type == "print":
                    # æ™®é€šprintè¾“å‡º
                    print(content, flush=True)
                elif output_type == "print_no_newline":
                    # printè¾“å‡ºï¼ˆä¸æ¢è¡Œï¼‰
                    print(content, end='', flush=True)
                elif output_type == "stdout_flush":
                    # stdout flush
                    sys.stdout.flush()
                
                self.output_queue.task_done()
            except queue.Empty:
                continue
            except Exception as e:
                # è¾“å‡ºå¤±è´¥ä¸åº”è¯¥å½±å“ä¸»ç¨‹åºï¼Œé™é»˜å¤„ç†
                pass
    
    def print(self, content):
        """å¼‚æ­¥printï¼ˆéé˜»å¡ï¼‰"""
        try:
            self.output_queue.put_nowait(("print", content))
        except queue.Full:
            # é˜Ÿåˆ—æ»¡æ—¶ï¼Œç›´æ¥è¾“å‡ºï¼ˆé¿å…ä¸¢å¤±é‡è¦ä¿¡æ¯ï¼‰
            print(content, flush=True)
    
    def print_no_newline(self, content):
        """å¼‚æ­¥printï¼ˆä¸æ¢è¡Œï¼Œéé˜»å¡ï¼‰"""
        try:
            self.output_queue.put_nowait(("print_no_newline", content))
        except queue.Full:
            print(content, end='', flush=True)
    
    def flush(self):
        """å¼‚æ­¥flushï¼ˆéé˜»å¡ï¼‰"""
        try:
            self.output_queue.put_nowait(("stdout_flush", None))
        except queue.Full:
            sys.stdout.flush()

# å…¨å±€å¼‚æ­¥è¾“å‡ºå®ä¾‹
_async_output = AsyncOutput()

def main():
    print("=" * 60)
    print("ä¸€é”®å®æ—¶éº¦å…‹é£è¯­éŸ³è¯†åˆ«")
    print("=" * 60)
    print()
    
    # åŠ è½½é…ç½®
    config_manager = None
    if CONFIG_MANAGER_AVAILABLE:
        config_manager = ConfigManager()
        print("âœ“ é…ç½®å·²åŠ è½½")
    else:
        print("âš  é…ç½®ç®¡ç†æ¨¡å—ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    
    # åˆå§‹åŒ–æ€§èƒ½æ˜¾ç¤º
    perf_display = None
    if PERFORMANCE_DISPLAY_AVAILABLE:
        ui_config = config_manager.get_ui_config() if config_manager else {}
        perf_config = config_manager.get_performance_monitor_config() if config_manager else {}
        perf_display = PerformanceDisplay(
            enable_colors=ui_config.get('show_colors', True),
            update_interval=perf_config.get('update_interval', 5.0)
        )
    
    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        if perf_display:
            perf_display.display_error("ä¾èµ–æ£€æŸ¥", "ç¼ºå°‘å¿…è¦çš„ä¾èµ–åŒ…", "è¯·è¿è¡Œ: pip install -r requirements.txt")
        sys.exit(1)
    
    import numpy as np
    import sounddevice as sd
    from whisper_online import FasterWhisperASR, WhisperTimestampedASR, OnlineASRProcessor, VACOnlineASRProcessor  # type: ignore
    
    # åˆ›å»ºæ”¯æŒè‡ªå®šä¹‰ device å’Œ compute_type çš„åŒ…è£…ç±»
    if ASR_COMPONENTS_AVAILABLE:
        CustomFasterWhisperASR = create_custom_faster_whisper_asr(FasterWhisperASR)
    else:
        # å›é€€åˆ°å†…ç½®å®ç°ï¼ˆå¦‚æœæ¨¡å—ä¸å¯ç”¨ï¼‰
        class CustomFasterWhisperASR(FasterWhisperASR):
            """æ”¯æŒè‡ªå®šä¹‰ deviceã€compute_type å’Œåº•å±‚å‚æ•°çš„ FasterWhisperASRï¼ˆå›é€€å®ç°ï¼‰"""
            def __init__(self, lan, modelsize=None, cache_dir=None, model_dir=None, 
                         device="cuda", compute_type="float16", 
                         device_index=0, num_workers=1, cpu_threads=None,
                         logfile=sys.stderr, adaptive_params=None, transcribe_kwargs=None):
                self.device = device
                self.compute_type = compute_type
                self.device_index = device_index
                self.num_workers = num_workers
                self.cpu_threads = cpu_threads
                self.logfile = logfile
                self.transcribe_kargs = transcribe_kwargs if transcribe_kwargs else {}
                self.adaptive_params = adaptive_params
                if lan == "auto":
                    self.original_language = None
                else:
                    self.original_language = lan
                self.model = self.load_model(modelsize, cache_dir, model_dir)
            
            def load_model(self, modelsize=None, cache_dir=None, model_dir=None):
                from faster_whisper import WhisperModel
                import logging
                logging.getLogger("faster_whisper").setLevel(logging.WARNING)
                if model_dir is not None:
                    model_size_or_path = model_dir
                elif modelsize is not None:
                    model_size_or_path = modelsize
                else:
                    raise ValueError("modelsize or model_dir parameter must be set")
                model_kwargs = {
                    'device': self.device,
                    'compute_type': self.compute_type,
                    'download_root': cache_dir,
                    'num_workers': self.num_workers,
                }
                if self.device == "cuda":
                    model_kwargs['device_index'] = self.device_index
                if self.device == "cpu" and self.cpu_threads is not None:
                    model_kwargs['num_workers'] = self.cpu_threads
                model = WhisperModel(model_size_or_path, **model_kwargs)
                return model
            
            def transcribe(self, audio, init_prompt=""):
                if self.adaptive_params:
                    adaptive_kwargs = self.adaptive_params.get_transcribe_kwargs()
                    transcribe_kwargs = {**self.transcribe_kargs, **adaptive_kwargs}
                else:
                    transcribe_kwargs = self.transcribe_kargs
                segments, info = self.model.transcribe(
                    audio, 
                    language=self.original_language, 
                    initial_prompt=init_prompt, 
                    beam_size=transcribe_kwargs.get('beam_size', 5),
                    temperature=transcribe_kwargs.get('temperature', 0.0),
                    word_timestamps=True, 
                    condition_on_previous_text=True, 
                    **{k: v for k, v in transcribe_kwargs.items() if k not in ['beam_size', 'temperature']}
                )
                return list(segments)
    
    # æ£€æµ‹ç¡¬ä»¶é…ç½®
    print("æ­£åœ¨æ£€æµ‹ç¡¬ä»¶é…ç½®...")
    try:
        import psutil
        hardware = detect_hardware()
        print(f"âœ“ ç¡¬ä»¶æ£€æµ‹å®Œæˆ")
        print(f"  - CPU: {hardware['cpu_cores']} ç‰©ç†æ ¸å¿ƒ / {hardware['cpu_threads']} é€»è¾‘æ ¸å¿ƒ")
        print(f"  - å†…å­˜: {hardware['ram_gb']} GB")
        if hardware['gpu_available']:
            print(f"  - GPU: {hardware['gpu_name']} ({hardware['gpu_memory_gb']} GB)")
        else:
            print(f"  - GPU: æœªæ£€æµ‹åˆ°æˆ–ä¸å¯ç”¨")
        print()
    except ImportError:
        print("âš  æœªå®‰è£… psutilï¼Œæ— æ³•æ£€æµ‹ç¡¬ä»¶é…ç½®")
        print("  å¯ä»¥å®‰è£…: pip install psutil")
        print("  å°†ä½¿ç”¨é»˜è®¤é…ç½®")
        hardware = {'cpu_cores': 8, 'cpu_threads': 16, 'ram_gb': 16, 'gpu_available': False, 'gpu_memory_gb': 0}
        print()
    except Exception as e:
        print(f"âš  ç¡¬ä»¶æ£€æµ‹å¤±è´¥: {e}")
        print("  å°†ä½¿ç”¨é»˜è®¤é…ç½®")
        hardware = {'cpu_cores': 8, 'cpu_threads': 16, 'ram_gb': 16, 'gpu_available': False, 'gpu_memory_gb': 0}
        print()
    
    # è¯¢é—®ç”¨æˆ·é€‰æ‹©è¿è¡Œæ¨¡å¼
    print("=" * 60)
    print("é€‰æ‹©è¿è¡Œæ¨¡å¼")
    print("=" * 60)
    if hardware['gpu_available']:
        print("æ£€æµ‹åˆ°å¯ç”¨ GPUï¼Œå¯ä»¥é€‰æ‹©ï¼š")
        print("  [1] GPU æ¨¡å¼ï¼ˆæ›´å¿«ï¼Œæ¨èï¼‰")
        print("  [2] CPU æ¨¡å¼ï¼ˆæ›´ç¨³å®šï¼Œä¸ä¾èµ– CUDAï¼‰")
    else:
        print("æœªæ£€æµ‹åˆ°å¯ç”¨ GPUï¼Œå°†ä½¿ç”¨ CPU æ¨¡å¼")
    
    use_gpu = False
    if hardware['gpu_available']:
        while True:
            try:
                choice = input("\nè¯·é€‰æ‹©è¿è¡Œæ¨¡å¼ (1/2ï¼Œç›´æ¥å›è½¦ä½¿ç”¨ GPU): ").strip()
                if choice == "" or choice == "1":
                    use_gpu = True
                    break
                elif choice == "2":
                    use_gpu = False
                    break
                else:
                    print("è¯·è¾“å…¥ 1 æˆ– 2")
            except KeyboardInterrupt:
                print("\né€€å‡ºç¨‹åº")
                sys.exit(0)
    else:
        use_gpu = False
        print("è‡ªåŠ¨é€‰æ‹© CPU æ¨¡å¼")
    
    print()
    
    # é€‰æ‹©è¯†åˆ«åç«¯
    print("=" * 60)
    print("é€‰æ‹©è¯†åˆ«åç«¯")
    print("=" * 60)
    print("  [1] faster-whisperï¼ˆæ¨èï¼Œé€Ÿåº¦å¿«ï¼Œçº¦4å€åŠ é€Ÿï¼‰")
    print("  [2] whisperï¼ˆåŸå§‹ç‰ˆæœ¬ï¼Œå®‰è£…ç®€å•ï¼ŒGPUæ”¯æŒæ›´å¥½ï¼‰")
    print()
    
    backend_choice = None
    while backend_choice is None:
        try:
            choice = input("è¯·é€‰æ‹©åç«¯ (ç›´æ¥å›è½¦ä½¿ç”¨ faster-whisper): ").strip()
            if choice == "" or choice == "1":
                backend_choice = "faster-whisper"
            elif choice == "2":
                backend_choice = "whisper"
            else:
                print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1 æˆ– 2")
        except KeyboardInterrupt:
            print("\nä½¿ç”¨é»˜è®¤åç«¯: faster-whisper")
            backend_choice = "faster-whisper"
            break
    
    print(f"âœ“ å·²é€‰æ‹©åç«¯: {backend_choice}")
    print()
    
    # æ ¹æ®ç¡¬ä»¶é…ç½®æ¨èå‚æ•°
    recommendations = recommend_config(hardware, use_gpu)
    
    print("=" * 60)
    print("æ¨èé…ç½®")
    print("=" * 60)
    print(f"è¿è¡Œè®¾å¤‡: {recommendations['device'].upper()}")
    print(f"æ¨èæ¨¡å‹: {recommendations['model_size']}")
    print(f"è®¡ç®—ç±»å‹: {recommendations['compute_type']}")
    for reason in recommendations['reason']:
        print(f"  - {reason}")
    print()
    
    # è¯¢é—®ç”¨æˆ·æ˜¯å¦ä½¿ç”¨æ¨èé…ç½®
    while True:
        try:
            confirm = input("æ˜¯å¦ä½¿ç”¨æ¨èé…ç½®ï¼Ÿ(y/nï¼Œç›´æ¥å›è½¦ä½¿ç”¨æ¨èé…ç½®): ").strip().lower()
            if confirm == "" or confirm in ['y', 'yes', 'æ˜¯']:
                model_size = recommendations['model_size']
                device = recommendations['device']
                compute_type = recommendations['compute_type']
                print(f"âœ“ å·²åº”ç”¨æ¨èé…ç½®: {model_size} æ¨¡å‹, {device.upper()} è®¾å¤‡, {compute_type} è®¡ç®—ç±»å‹")
                break
            elif confirm in ['n', 'no', 'å¦']:
                # è®©ç”¨æˆ·æ‰‹åŠ¨é€‰æ‹©æ¨¡å‹
                print("\nå¯ç”¨æ¨¡å‹: tiny, base, small, medium, large-v2, large-v3")
                model_choice = input("è¯·é€‰æ‹©æ¨¡å‹ (ç›´æ¥å›è½¦ä½¿ç”¨ medium): ").strip().lower()
                if model_choice == "":
                    model_size = "medium"
                elif model_choice in ['tiny', 'base', 'small', 'medium', 'large-v2', 'large-v3']:
                    model_size = model_choice
                else:
                    print("æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨ medium")
                    model_size = "medium"
                
                if use_gpu:
                    device = "cuda"
                    compute_type = "float16"
                else:
                    device = "cpu"
                    compute_type = "int8"
                
                print(f"âœ“ å·²åº”ç”¨è‡ªå®šä¹‰é…ç½®: {model_size} æ¨¡å‹, {device.upper()} è®¾å¤‡, {compute_type} è®¡ç®—ç±»å‹")
                
                # å¦‚æœé€‰æ‹©äº†å¤§æ¨¡å‹ï¼Œç»™å‡ºæç¤º
                if model_size in ['large-v2', 'large-v3', 'large']:
                    print()
                    print("âš  æ³¨æ„ï¼šå¤§æ¨¡å‹ (large-v2/v3) åœ¨å®æ—¶åœºæ™¯ä¸‹ï¼š")
                    print("  - å¤„ç†é€Ÿåº¦è¾ƒæ…¢ï¼ˆå»¶è¿Ÿè¾ƒé«˜ï¼‰")
                    print("  - éœ€è¦æ›´å¤šæ˜¾å­˜å’Œè®¡ç®—èµ„æº")
                    print("  - å»ºè®®ä½¿ç”¨ medium æ¨¡å‹ä»¥è·å¾—æ›´å¥½çš„å®æ—¶ä½“éªŒ")
                    print()
                
                break
            else:
                print("è¯·è¾“å…¥ y æˆ– n")
        except KeyboardInterrupt:
            print("\né€€å‡ºç¨‹åº")
            sys.exit(0)
    
    # ä¼˜åŒ–åº•å±‚å‚æ•°
    print("æ­£åœ¨ä¼˜åŒ–åº•å±‚å‚æ•°...")
    low_level_params = optimize_low_level_params(hardware, use_gpu, model_size)
    if 'reason' in low_level_params:
        print("åº•å±‚ä¼˜åŒ–:")
        for line in low_level_params['reason'].split('\n'):
            if line.strip():
                print(f"  {line.strip()}")
    print()
    
    # äººå£°åˆ†ç¦»æ¨¡å‹æ¨èå’Œé€‰æ‹©ï¼ˆå¦‚æœå¯ç”¨äº†äººå£°åˆ†ç¦»ï¼‰
    if VOCAL_SEPARATION_AVAILABLE and config_manager:
        sep_config = config_manager.get("vocal_separation", {})
        if sep_config.get("enable", False):
            method = sep_config.get("method", "demucs").lower()
            
            # Demucs æ¨¡å‹æ¨èå’Œé€‰æ‹©
            if method == "demucs":
                print("=" * 60)
                print("Demucs æ¨¡å‹æ¨è")
                print("=" * 60)
                
                # å¦‚æœå¯ç”¨äº†GPUï¼Œè¿›è¡Œæ˜¾å­˜æ¨è
                if use_gpu and hardware['gpu_available']:
                    demucs_recommendations = recommend_demucs_config(hardware, use_gpu, model_size)
                    for reason in demucs_recommendations['reason']:
                        print(f"  {reason}")
                    if demucs_recommendations['warnings']:
                        print()
                        for warning in demucs_recommendations['warnings']:
                            print(f"  {warning}")
                    print()
                    
                    # å¦‚æœæ¨èäº†æ¨¡å‹ï¼Œè®©ç”¨æˆ·é€‰æ‹©
                    if demucs_recommendations['demucs_model']:
                        recommended_model = demucs_recommendations['demucs_model']
                        current_model = sep_config.get("demucs_model", "").strip()
                        
                        print(f"æ¨èæ¨¡å‹: {recommended_model}")
                        if current_model:
                            print(f"å½“å‰é…ç½®: {current_model}")
                        
                        print("\nå¯ç”¨æ¨¡å‹:")
                        print("  [1] htdemucs - è½»é‡çº§ï¼Œ~1.5-2GBæ˜¾å­˜ï¼ˆæ¨èå®æ—¶ï¼‰")
                        print("  [2] htdemucs_ft - æ›´é«˜è´¨é‡ï¼Œ~3-4GBæ˜¾å­˜")
                        print("  [3] htdemucs_6s - 6ç§éŸ³æºåˆ†ç¦»ï¼Œ~2-2.5GBæ˜¾å­˜")
                        print("  [4] hdemucs_mmi - æ··åˆæ¨¡å‹ï¼Œ~2.5-3GBæ˜¾å­˜")
                        print("  [5] mdx - é«˜è´¨é‡ï¼Œ~2-3GBæ˜¾å­˜")
                        print("  [6] mdx_extra - æœ€é«˜è´¨é‡ï¼Œ~3-4GBæ˜¾å­˜")
                        
                        model_map = {
                            '1': 'htdemucs',
                            '2': 'htdemucs_ft',
                            '3': 'htdemucs_6s',
                            '4': 'hdemucs_mmi',
                            '5': 'mdx',
                            '6': 'mdx_extra'
                        }
                        
                        try:
                            choice = input(f"\nè¯·é€‰æ‹©æ¨¡å‹ (1-6ï¼Œç›´æ¥å›è½¦ä½¿ç”¨æ¨è {recommended_model}): ").strip()
                            if choice == "":
                                selected_model = recommended_model
                            elif choice in model_map:
                                selected_model = model_map[choice]
                            else:
                                print(f"æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨æ¨èæ¨¡å‹: {recommended_model}")
                                selected_model = recommended_model
                            
                            # æ›´æ–°é…ç½®
                            sep_config["demucs_model"] = selected_model
                            config_manager.set("vocal_separation", sep_config)
                            config_manager.save()
                            print(f"âœ“ å·²æ›´æ–° config.json: demucs_model = {selected_model}")
                            print()
                        except KeyboardInterrupt:
                            print("\nä½¿ç”¨å½“å‰é…ç½®")
                            print()
                    elif not demucs_recommendations['enable']:
                        print("âš  å»ºè®®ï¼šæ ¹æ®å½“å‰æ˜¾å­˜æƒ…å†µï¼Œä¸å»ºè®®å¯ç”¨ Demucs")
                        print("  å¯ä»¥è€ƒè™‘ä½¿ç”¨ filter æ–¹æ³•ï¼ˆé¢‘åŸŸæ»¤æ³¢ï¼‰æˆ–å…³é—­äººå£°åˆ†ç¦»")
                        print()
                else:
                    # CPUæ¨¡å¼æˆ–æ²¡æœ‰GPUï¼Œæä¾›åŸºæœ¬é€‰æ‹©
                    current_model = sep_config.get("demucs_model", "").strip()
                    if not current_model:
                        print("âš  CPUæ¨¡å¼ä¸‹ä¸æ¨èä½¿ç”¨Demucsï¼ˆé€Ÿåº¦å¤ªæ…¢ï¼‰")
                        print("  å»ºè®®ä½¿ç”¨ filter æ–¹æ³•æˆ–å…³é—­äººå£°åˆ†ç¦»")
                        print()
                    else:
                        print(f"å½“å‰é…ç½®: {current_model}")
                        print("âš  æ³¨æ„ï¼šCPUæ¨¡å¼ä¸‹Demucså¤„ç†é€Ÿåº¦è¾ƒæ…¢ï¼Œå¯èƒ½å½±å“å®æ—¶æ€§")
                        print()
            
            # Spleeter æ¨¡å‹æ¨èå’Œé€‰æ‹©
            elif method == "spleeter":
                print("=" * 60)
                print("Spleeter æ¨¡å‹é€‰æ‹©")
                print("=" * 60)
                print("å¯ç”¨æ¨¡å‹:")
                print("  [1] 2stems - äººå£°+ä¼´å¥ï¼ˆæ¨èï¼Œæœ€å¿«ï¼‰")
                print("  [2] 4stems - äººå£°ã€é¼“ã€è´æ–¯ã€å…¶ä»–")
                print("  [3] 5stems - äººå£°ã€é¼“ã€è´æ–¯ã€é’¢ç´ã€å…¶ä»–")
                
                current_model = sep_config.get("spleeter_model", "2stems")
                print(f"\nå½“å‰é…ç½®: {current_model}")
                
                model_map = {
                    '1': '2stems',
                    '2': '4stems',
                    '3': '5stems'
                }
                
                try:
                    choice = input("è¯·é€‰æ‹©æ¨¡å‹ (1-3ï¼Œç›´æ¥å›è½¦ä¿æŒå½“å‰é…ç½®): ").strip()
                    if choice in model_map:
                        selected_model = model_map[choice]
                        sep_config["spleeter_model"] = selected_model
                        config_manager.set("vocal_separation", sep_config)
                        config_manager.save()
                        print(f"âœ“ å·²æ›´æ–° config.json: spleeter_model = {selected_model}")
                    elif choice == "":
                        print("ä¿æŒå½“å‰é…ç½®")
                    else:
                        print("æ— æ•ˆé€‰æ‹©ï¼Œä¿æŒå½“å‰é…ç½®")
                    print()
                except KeyboardInterrupt:
                    print("\nä¿æŒå½“å‰é…ç½®")
                    print()
    
    # é‡æ–°åŠ è½½é…ç½®ï¼ˆå¦‚æœç”¨æˆ·æ›´æ–°äº†æ¨¡å‹é…ç½®ï¼‰
    if config_manager:
        config_manager.load_config()
    
    # é…ç½®å‚æ•°
    SAMPLING_RATE = 16000  # Whisper éœ€è¦çš„é‡‡æ ·ç‡
    CHUNK_DURATION = 1.0   # åŸºç¡€å¤„ç†é—´éš”ï¼ˆVAC æ¨¡å¼ä¸‹ä¼šè‡ªåŠ¨è°ƒæ•´ï¼‰
    
    # VAC (Voice Activity Controller) é…ç½®
    # VAC ä½¿ç”¨è¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼Œä¼šåœ¨æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸæ—¶ï¼ˆ500ms é™éŸ³ï¼‰è‡ªåŠ¨å¤„ç†
    # è¿™æ ·å¯ä»¥å®ç°æŒ‰å¥å­/åŠå¥å¤„ç†ï¼Œè€Œä¸æ˜¯å›ºå®šæ—¶é—´é—´éš”
    use_vac = True  # æ˜¯å¦ä½¿ç”¨ VACï¼ˆæ¨èå¯ç”¨ï¼Œå®ç°æŒ‰å¥å­å¤„ç†ï¼‰
    
    # ä»é…ç½®æ–‡ä»¶è¯»å–ä¼˜åŒ–å‚æ•°ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if CONFIG_MANAGER_AVAILABLE and config_manager:
        asr_opt = config_manager.get("asr_optimization", {})
        vac_chunk_size = asr_opt.get("vac_chunk_size", 0.08)  # é»˜è®¤0.08ç§’ï¼ˆå¢åŠ ä¸Šä¸‹æ–‡ï¼‰
        agreement_n = asr_opt.get("agreement_n", 3)  # é»˜è®¤3ï¼ˆæ›´å‡†ç¡®ï¼‰
        vad_initial_silence_ms = config_manager.get("speech_rate_adaptive.initial_silence_ms", 1000)
        vad_min_silence_ms = config_manager.get("speech_rate_adaptive.min_silence_ms", 500)
        vad_max_silence_ms = config_manager.get("speech_rate_adaptive.max_silence_ms", 1500)
        beam_size = asr_opt.get("beam_size", 5)
        temperature = asr_opt.get("temperature", 0.0)
        print(f"âœ“ å·²åŠ è½½ASRä¼˜åŒ–é…ç½®: agreement_n={agreement_n}, vac_chunk_size={vac_chunk_size}, VADé™éŸ³={vad_min_silence_ms}-{vad_max_silence_ms}ms")
    else:
        vac_chunk_size = 0.08  # é»˜è®¤å€¼ï¼š0.08ç§’ï¼ˆå¢åŠ ä¸Šä¸‹æ–‡ï¼‰
        agreement_n = 3  # é»˜è®¤å€¼ï¼š3ï¼ˆæ›´å‡†ç¡®ï¼‰
        vad_initial_silence_ms = 1000
        vad_min_silence_ms = 500
        vad_max_silence_ms = 1500
        vad_threshold = 0.6  # é»˜è®¤0.6ï¼Œå‡å°‘èƒŒæ™¯éŸ³ä¹å¹²æ‰°
        beam_size = 5
        temperature = 0.0
    
    # è¯­è¨€å’Œæ¨¡å‹é…ç½®
    # è¾“å‡ºä¸­æ–‡ï¼šè®¾ç½® input_language="zh" æˆ– "auto"ï¼Œtask="transcribe"
    # è¾“å‡ºè‹±æ–‡ï¼šè®¾ç½® input_language="en" æˆ– "auto"ï¼Œtask="transcribe"
    # ä¸­æ–‡ç¿»è¯‘æˆè‹±æ–‡ï¼šè®¾ç½® input_language="zh"ï¼Œtask="translate"
    # æ³¨æ„ï¼štranslate æ¨¡å¼åªèƒ½ç¿»è¯‘æˆè‹±æ–‡ï¼Œä¸èƒ½ç¿»è¯‘æˆå…¶ä»–è¯­è¨€
    # é»˜è®¤è¯­è¨€ï¼ˆå¦‚æœç”¨æˆ·ä¸é€‰æ‹©ï¼Œå°†ä½¿ç”¨æ­¤å€¼ï¼‰
    default_language = "auto"  # è¾“å…¥è¯­éŸ³çš„è¯­è¨€: "zh"ï¼ˆä¸­æ–‡ï¼‰ã€"en"ï¼ˆè‹±æ–‡ï¼‰ã€"auto"ï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰ç­‰
    task = "transcribe"      # ä»»åŠ¡ç±»å‹: "transcribe"ï¼ˆè½¬å½•ï¼Œè¾“å‡ºä¸è¾“å…¥ç›¸åŒçš„è¯­è¨€ï¼‰æˆ– "translate"ï¼ˆç¿»è¯‘æˆè‹±æ–‡ï¼‰
    # model_size å·²åœ¨ä¸Šé¢æ ¹æ®ç¡¬ä»¶é…ç½®è®¾ç½®
    
    # è®©ç”¨æˆ·é€‰æ‹©è¯†åˆ«è¯­è¨€ï¼ˆåœ¨åŠ è½½æ¨¡å‹ä¹‹å‰ï¼‰
    print("=" * 60)
    print("é€‰æ‹©è¯†åˆ«è¯­è¨€")
    print("=" * 60)
    print("å¸¸ç”¨è¯­è¨€ä»£ç : zh(ä¸­æ–‡), en(è‹±æ–‡), ja(æ—¥æ–‡), ko(éŸ©æ–‡), es(è¥¿ç­ç‰™è¯­), fr(æ³•è¯­), de(å¾·è¯­), ru(ä¿„è¯­)")
    print("å®Œæ•´è¯­è¨€åˆ—è¡¨: af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,zh,yue")
    print()
    
    # è¯­è¨€ä»£ç éªŒè¯åˆ—è¡¨
    valid_languages = ['auto', 'zh', 'en', 'ja', 'ko', 'es', 'fr', 'de', 'ru', 'it', 'pt', 'ar', 'hi', 'th', 'vi', 'id', 'nl', 'pl', 'tr', 'cs', 'sv', 'no', 'da', 'fi', 'el', 'he', 'uk', 'ro', 'hu', 'bg', 'hr', 'sk', 'sl', 'et', 'lv', 'lt', 'mt', 'ga', 'cy', 'af', 'am', 'as', 'az', 'ba', 'be', 'bn', 'bo', 'br', 'bs', 'ca', 'eu', 'fa', 'fo', 'gl', 'gu', 'ha', 'haw', 'hy', 'is', 'jw', 'ka', 'kk', 'km', 'kn', 'la', 'lb', 'ln', 'lo', 'mg', 'mi', 'mk', 'ml', 'mn', 'mr', 'ms', 'my', 'ne', 'nn', 'oc', 'pa', 'ps', 'sa', 'sd', 'si', 'sn', 'so', 'sq', 'sr', 'su', 'sw', 'ta', 'te', 'tg', 'tk', 'tl', 'tt', 'ur', 'uz', 'yi', 'yo', 'yue']
    
    input_language = None
    while input_language is None:
        try:
            lang_choice = input(f"è¯·è¾“å…¥è¯­è¨€ä»£ç ï¼ˆç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤: {default_language}ï¼‰: ").strip()
            if not lang_choice:
                # ä½¿ç”¨é»˜è®¤è¯­è¨€
                input_language = default_language
            else:
                lang_choice = lang_choice.lower()
                if lang_choice in valid_languages:
                    input_language = lang_choice
                else:
                    print(f"âš  æœªè¯†åˆ«çš„è¯­è¨€ä»£ç  '{lang_choice}'ï¼Œè¯·é‡æ–°è¾“å…¥")
                    print("æç¤º: è¾“å…¥ 'auto' å¯è‡ªåŠ¨æ£€æµ‹è¯­è¨€")
        except KeyboardInterrupt:
            print("\nä½¿ç”¨é»˜è®¤è¯­è¨€")
            input_language = default_language
            break
    
    print(f"âœ“ å·²é€‰æ‹©è¯­è¨€: {input_language} ({'è‡ªåŠ¨æ£€æµ‹' if input_language == 'auto' else input_language})")
    print()
    
    # è®©ç”¨æˆ·é€‰æ‹©ä»»åŠ¡ç±»å‹ï¼ˆåœ¨åŠ è½½æ¨¡å‹ä¹‹å‰ï¼‰
    print("=" * 60)
    print("é€‰æ‹©ä»»åŠ¡ç±»å‹")
    print("=" * 60)
    print("  - transcribe: è½¬å½•æ¨¡å¼ï¼Œè¾“å‡ºä¸è¾“å…¥ç›¸åŒçš„è¯­è¨€")
    print("  - translate: ç¿»è¯‘æ¨¡å¼ï¼Œç›´æ¥ç¿»è¯‘æˆè‹±æ–‡ï¼ˆå¦‚æœæ‡‚è‹±è¯­ï¼Œæ¨èé€‰æ‹©æ­¤é€‰é¡¹ï¼‰")
    print()
    
    default_task = "transcribe"
    task = None
    while task is None:
        try:
            task_choice = input(f"è¯·è¾“å…¥ä»»åŠ¡ç±»å‹ï¼ˆç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤: {default_task}ï¼‰: ").strip().lower()
            if not task_choice:
                task = default_task
            elif task_choice in ["transcribe", "translate"]:
                task = task_choice
            else:
                print(f"âš  æ— æ•ˆçš„ä»»åŠ¡ç±»å‹ '{task_choice}'ï¼Œè¯·è¾“å…¥ 'transcribe' æˆ– 'translate'")
        except KeyboardInterrupt:
            print("\nä½¿ç”¨é»˜è®¤ä»»åŠ¡ç±»å‹")
            task = default_task
            break
    
    print(f"âœ“ å·²é€‰æ‹©ä»»åŠ¡ç±»å‹: {task} ({'è½¬å½•' if task == 'transcribe' else 'ç¿»è¯‘æˆè‹±æ–‡'})")
    print()
    
    # æ ¹æ®è¯­è¨€é‡æ–°è¯»å–é…ç½®ï¼ˆè¯­è¨€ç‰¹å®šé…ç½®ä¼˜å…ˆï¼‰
    if CONFIG_MANAGER_AVAILABLE and config_manager:
        # è·å–è¯­è¨€ç‰¹å®šçš„ ASR ä¼˜åŒ–é…ç½®
        asr_opt = config_manager.get_language_specific_config(input_language, "asr_optimization")
        vac_chunk_size = asr_opt.get("vac_chunk_size", 0.08)
        agreement_n = asr_opt.get("agreement_n", 3)
        beam_size = asr_opt.get("beam_size", 5)
        temperature = asr_opt.get("temperature", 0.0)
        vad_threshold = asr_opt.get("vad_threshold", 0.6)
        
        # è·å–è¯­è¨€ç‰¹å®šçš„è¯­é€Ÿè‡ªé€‚åº”é…ç½®
        speech_rate_config = config_manager.get_language_specific_config(input_language, "speech_rate_adaptive")
        vad_initial_silence_ms = speech_rate_config.get("initial_silence_ms", 1000)
        vad_min_silence_ms = speech_rate_config.get("min_silence_ms", 500)
        vad_max_silence_ms = speech_rate_config.get("max_silence_ms", 1500)
        
        print(f"âœ“ å·²åŠ è½½è¯­è¨€ç‰¹å®šé…ç½® ({input_language}): agreement_n={agreement_n}, vac_chunk_size={vac_chunk_size}, VADé™éŸ³={vad_min_silence_ms}-{vad_max_silence_ms}ms")
    else:
        # æ²¡æœ‰é…ç½®ç®¡ç†å™¨ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼ˆå·²åœ¨å‰é¢è®¾ç½®ï¼‰
        pass
    
    # ========== ç¿»è¯‘åŠŸèƒ½é…ç½® ==========
    # å¦‚æœtaskæ˜¯translateï¼Œä¸éœ€è¦APIç¿»è¯‘ï¼ˆWhisperç›´æ¥ç¿»è¯‘æˆè‹±æ–‡ï¼‰
    # å¦‚æœtaskæ˜¯transcribeï¼Œéœ€è¦APIç¿»è¯‘æˆä¸­æ–‡
    enable_translation = (task == "transcribe")
    
    # åˆå§‹åŒ–ç¿»è¯‘ç®¡ç†å™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
    translation_manager = None
    translate_interval = 10.0  # é»˜è®¤å€¼
    if enable_translation:
        try:
            from translation_manager import TranslationManager
            
            # ä»é…ç½®è·å–ç¿»è¯‘é—´éš”
            if CONFIG_MANAGER_AVAILABLE and config_manager:
                translate_interval = config_manager.get("translate_interval", 10.0)
            
            # å®šä¹‰ç¿»è¯‘ç»“æœè¾“å‡ºå›è°ƒï¼ˆä½¿ç”¨å¼‚æ­¥è¾“å‡ºï¼Œä¸è¯†åˆ«ç»“æœä¿æŒä¸€è‡´ï¼‰
            def translation_output_callback(original_text: str, translated_text: str):
                """ç¿»è¯‘ç»“æœè¾“å‡ºå›è°ƒ"""
                # ä½¿ç”¨å…¨å±€çš„å¼‚æ­¥è¾“å‡ºå®ä¾‹
                _async_output.print(f"ğŸŒ {translated_text}")
                _async_output.flush()
            
            translation_manager = TranslationManager(
                translate_interval=translate_interval,
                output_callback=translation_output_callback
            )
            translation_manager.start()
            print(f"âœ“ ç¿»è¯‘ç®¡ç†å™¨å·²å¯åŠ¨ï¼ˆé—´éš”: {translate_interval}ç§’ï¼‰")
        except ImportError:
            print("âš  ç¿»è¯‘ç®¡ç†å™¨æ¨¡å—ä¸å¯ç”¨ï¼Œç¿»è¯‘åŠŸèƒ½å°†ç¦ç”¨")
            enable_translation = False
        except Exception as e:
            print(f"âš  ç¿»è¯‘ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œç¿»è¯‘åŠŸèƒ½å°†ç¦ç”¨")
            enable_translation = False
    
    # è¯­è¨€ä»£ç åˆ—è¡¨ï¼ˆå¸¸ç”¨ï¼‰
    # å®Œæ•´åˆ—è¡¨: af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,zh,yue
    
    # ç¡®å®šè¾“å‡ºè¯­è¨€
    if task == "translate":
        output_language = "è‹±æ–‡"
    elif input_language == "auto":
        output_language = "è‡ªåŠ¨æ£€æµ‹ï¼ˆä¸è¾“å…¥ç›¸åŒï¼‰"
    else:
        output_language = input_language
    
    print(f"é…ç½®:")
    print(f"  - è¾“å…¥è¯­è¨€: {input_language}")
    if input_language == "auto":
        print("    âš  æç¤º: å¦‚æœçŸ¥é“è¾“å…¥è¯­è¨€ï¼Œå»ºè®®æ˜ç¡®æŒ‡å®šï¼ˆå¦‚ 'zh' ä¸­æ–‡ï¼‰ä»¥æé«˜è¯†åˆ«å‡†ç¡®åº¦")
    print(f"  - è¾“å‡ºè¯­è¨€: {output_language}")
    print(f"  - ä»»åŠ¡ç±»å‹: {task} ({'è½¬å½•' if task == 'transcribe' else 'ç¿»è¯‘æˆè‹±æ–‡'})")
    print(f"  - æ¨¡å‹: {model_size}")
    if model_size in ['large-v2', 'large-v3', 'large']:
        print("    âš  æ³¨æ„: å¤§æ¨¡å‹åœ¨å®æ—¶åœºæ™¯ä¸‹é€Ÿåº¦è¾ƒæ…¢ï¼Œå»ºè®®ä½¿ç”¨ medium")
    if use_vac:
        print(f"  - VAC (è¯­éŸ³æ´»åŠ¨æ£€æµ‹): å·²å¯ç”¨")
        print(f"    âœ“ è‡ªåŠ¨æŒ‰å¥å­/åŠå¥å¤„ç†ï¼ˆæ£€æµ‹åˆ° 500ms é™éŸ³æ—¶è§¦å‘ï¼‰")
        print(f"    âœ“ æ›´è‡ªç„¶çš„è¯†åˆ«èŠ‚å¥ï¼Œå‡å°‘å»¶è¿Ÿ")
    else:
        print(f"  - VAC (è¯­éŸ³æ´»åŠ¨æ£€æµ‹): æœªå¯ç”¨")
        print(f"    âš  å°†ä½¿ç”¨å›ºå®šæ—¶é—´é—´éš”å¤„ç†")
    if enable_translation:
        print(f"  - APIç¿»è¯‘: å·²å¯ç”¨ï¼ˆå°†ç¿»è¯‘æˆä¸­æ–‡ï¼Œé—´éš”: {translate_interval}ç§’ï¼‰")
    else:
        if task == "translate":
            print(f"  - APIç¿»è¯‘: ä¸éœ€è¦ï¼ˆWhisperç›´æ¥ç¿»è¯‘æˆè‹±æ–‡ï¼‰")
        else:
            print(f"  - APIç¿»è¯‘: å·²ç¦ç”¨")
    print(f"  - é‡‡æ ·ç‡: {SAMPLING_RATE} Hz")
    if not use_vac:
        # åªæœ‰é VAC æ¨¡å¼æ‰æ˜¾ç¤ºå¤„ç†é—´éš”
        if model_size in ['large-v2', 'large-v3', 'large']:
            actual_interval = max(CHUNK_DURATION, 2.0)
            print(f"  - å¤„ç†é—´éš”: {actual_interval} ç§’ (å¤§æ¨¡å‹è‡ªåŠ¨è°ƒæ•´ä¸ºæ›´é•¿é—´éš”)")
        else:
            print(f"  - å¤„ç†é—´éš”: {CHUNK_DURATION} ç§’")
    print()
    
    # åˆ›å»º ASR å¯¹è±¡
    asr = None
    load_errors = []
    
    if backend_choice == "whisper":
        # ä½¿ç”¨åŸå§‹ whisper åç«¯
        print(f"æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹ ({model_size})...")
        model_cache_dir = os.path.join(os.path.dirname(__file__), "models")
        try:
            asr = WhisperTimestampedASR(lan=input_language, modelsize=model_size, cache_dir=model_cache_dir)
            if task == "translate":
                asr.set_translate_task()
            print("âœ“ Whisper æ¨¡å‹åŠ è½½æˆåŠŸ")
        except ImportError as e:
            print(f"âœ— æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("æç¤º: ç¡®ä¿å·²å®‰è£… whisper å’Œ whisper-timestamped:")
            print("  pip install openai-whisper whisper-timestamped")
            sys.exit(1)
        except Exception as e:
            print(f"âœ— æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("æç¤º: ç¡®ä¿å·²å®‰è£… whisper: pip install openai-whisper whisper-timestamped")
            sys.exit(1)
    else:
        # ä½¿ç”¨ faster-whisper åç«¯
        print(f"æ­£åœ¨åŠ è½½ fast-Whisper æ¨¡å‹ ({model_size}, {device.upper()}, {compute_type})...")
        model_cache_dir = os.path.join(os.path.dirname(__file__), "models_fast")
        
        # å°è¯•åŠ è½½æ¨¡å‹ï¼ˆåº”ç”¨åº•å±‚ä¼˜åŒ–å‚æ•°ï¼‰
        if device == "cuda":
            try:
                # åˆ›å»ºtranscribe_kwargsï¼ŒåŒ…å«beam_sizeå’Œtemperature
                transcribe_kwargs = {
                    'beam_size': beam_size,
                    'temperature': temperature
                }
                asr = CustomFasterWhisperASR(
                    lan=input_language, 
                    modelsize=model_size, 
                    cache_dir=model_cache_dir,
                    device="cuda",
                    compute_type=compute_type,
                    device_index=low_level_params['device_index'],
                    num_workers=low_level_params['num_workers'],
                    transcribe_kwargs=transcribe_kwargs
                )
                print("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸï¼ˆGPU æ¨¡å¼ï¼‰")
                if low_level_params['device_index'] > 0:
                    print(f"  ä½¿ç”¨ GPU {low_level_params['device_index']}")
            except Exception as e:
                load_errors.append(("GPU", e))
                print(f"âš  GPU åŠ è½½å¤±è´¥: {e}")
                print("  å°è¯•è‡ªåŠ¨åˆ‡æ¢åˆ° CPU æ¨¡å¼...")
                device = "cpu"
                compute_type = "int8"
                # é‡æ–°ä¼˜åŒ– CPU å‚æ•°
                low_level_params = optimize_low_level_params(hardware, False, model_size)
        
        if asr is None:
            # CPU æ¨¡å¼æˆ– GPU å¤±è´¥åä½¿ç”¨ CPU
            try:
                # åˆ›å»ºtranscribe_kwargsï¼ŒåŒ…å«beam_sizeå’Œtemperature
                transcribe_kwargs = {
                    'beam_size': beam_size,
                    'temperature': temperature
                }
                asr = CustomFasterWhisperASR(
                    lan=input_language, 
                    modelsize=model_size, 
                    cache_dir=model_cache_dir,
                    device="cpu",
                    compute_type="int8",
                    num_workers=low_level_params['num_workers'],
                    cpu_threads=low_level_params.get('cpu_threads'),
                    transcribe_kwargs=transcribe_kwargs
                )
                print("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸï¼ˆCPU æ¨¡å¼ï¼‰")
                if low_level_params.get('cpu_threads'):
                    print(f"  ä½¿ç”¨ {low_level_params['cpu_threads']} ä¸ª CPU çº¿ç¨‹")
            except Exception as e:
                print(f"âœ— CPU æ¨¡å¼ä¹ŸåŠ è½½å¤±è´¥: {e}")
                print("æç¤º: ç¡®ä¿å·²å®‰è£… faster-whisper: pip install faster-whisper")
                if load_errors:
                    print("\nGPU åŠ è½½é”™è¯¯è¯¦æƒ…:")
                    for mode, error in load_errors:
                        print(f"  {mode}: {error}")
                sys.exit(1)
    
    # è®¾ç½®ä»»åŠ¡ç±»å‹ï¼ˆtranslate æ¨¡å¼ï¼‰
    if task == "translate":
        asr.set_translate_task()
        print("âœ“ å·²è®¾ç½®ä¸ºç¿»è¯‘æ¨¡å¼ï¼ˆå°†ç¿»è¯‘æˆè‹±æ–‡ï¼‰")
    
    def list_audio_devices(force_refresh=False):
        """åˆ—å‡ºå¯ç”¨çš„éŸ³é¢‘è¾“å…¥è®¾å¤‡"""
        if force_refresh:
            # å¼ºåˆ¶åˆ·æ–°è®¾å¤‡åˆ—è¡¨
            # æ³¨æ„ï¼šsounddevice çš„ query_devices() æ¯æ¬¡éƒ½ä¼šé‡æ–°æŸ¥è¯¢ç³»ç»Ÿè®¾å¤‡
            # ä½†å¦‚æœç³»ç»Ÿåˆšè¯†åˆ«åˆ°æ–°è®¾å¤‡ï¼Œå¯èƒ½éœ€è¦çŸ­æš‚ç­‰å¾…
            print("æ­£åœ¨åˆ·æ–°è®¾å¤‡åˆ—è¡¨ï¼Œè¯·ç¨å€™...")
            time.sleep(0.2)  # çŸ­æš‚ç­‰å¾…ï¼Œè®©ç³»ç»Ÿæœ‰æ—¶é—´è¯†åˆ«æ–°è®¾å¤‡
        
        # é‡æ–°æŸ¥è¯¢è®¾å¤‡åˆ—è¡¨ï¼ˆæ¯æ¬¡éƒ½ä¼šé‡æ–°æŸ¥è¯¢ç³»ç»Ÿè®¾å¤‡åˆ—è¡¨ï¼‰
        devices = sd.query_devices()
        input_devices = [d for d in devices if d['max_input_channels'] > 0]
        default_input = sd.query_devices(kind='input')['name']
        
        print("å¯ç”¨çš„éŸ³é¢‘è¾“å…¥è®¾å¤‡:")
        for i, dev in enumerate(input_devices):
            default = " (é»˜è®¤)" if dev['name'] == default_input else ""
            print(f"  [{i}] {dev['name']}{default}")
        print()
        return input_devices
    
    def select_device(input_devices):
        """è®©ç”¨æˆ·é€‰æ‹©éŸ³é¢‘è®¾å¤‡"""
        if len(input_devices) == 1:
            print(f"è‡ªåŠ¨é€‰æ‹©å”¯ä¸€è®¾å¤‡: {input_devices[0]['name']}")
            return 0
        
        while True:
            try:
                choice = input("è¯·é€‰æ‹©è®¾å¤‡ç¼–å·ï¼ˆç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤è®¾å¤‡ï¼Œè¾“å…¥ 'r' åˆ·æ–°è®¾å¤‡åˆ—è¡¨ï¼‰: ").strip()
                if choice.lower() == 'r':
                    # åˆ·æ–°è®¾å¤‡åˆ—è¡¨
                    print("\næ­£åœ¨åˆ·æ–°è®¾å¤‡åˆ—è¡¨...")
                    refreshed_devices = list_audio_devices(force_refresh=True)
                    if len(refreshed_devices) != len(input_devices):
                        print(f"âœ“ æ£€æµ‹åˆ°è®¾å¤‡å˜åŒ–ï¼ˆä¹‹å‰: {len(input_devices)} ä¸ªï¼Œç°åœ¨: {len(refreshed_devices)} ä¸ªï¼‰")
                        input_devices = refreshed_devices
                    else:
                        # æ£€æŸ¥è®¾å¤‡åç§°æ˜¯å¦æœ‰å˜åŒ–
                        old_names = {dev['name'] for dev in input_devices}
                        new_names = {dev['name'] for dev in refreshed_devices}
                        if old_names != new_names:
                            print(f"âœ“ æ£€æµ‹åˆ°è®¾å¤‡å˜åŒ–")
                            input_devices = refreshed_devices
                        else:
                            print("è®¾å¤‡åˆ—è¡¨æœªå˜åŒ–")
                    continue
                elif choice == "":
                    # ä½¿ç”¨é»˜è®¤è®¾å¤‡
                    default_input = sd.query_devices(kind='input')
                    for i, dev in enumerate(input_devices):
                        if dev['name'] == default_input['name']:
                            return i
                    return 0  # å¦‚æœæ‰¾ä¸åˆ°ï¼Œè¿”å›ç¬¬ä¸€ä¸ª
                else:
                    device_idx = int(choice)
                    if 0 <= device_idx < len(input_devices):
                        return device_idx
                    else:
                        print(f"æ— æ•ˆçš„è®¾å¤‡ç¼–å·ï¼Œè¯·è¾“å…¥ 0-{len(input_devices)-1} ä¹‹é—´çš„æ•°å­—ï¼Œæˆ–è¾“å…¥ 'r' åˆ·æ–°è®¾å¤‡åˆ—è¡¨")
            except ValueError:
                print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—ï¼Œæˆ–è¾“å…¥ 'r' åˆ·æ–°è®¾å¤‡åˆ—è¡¨")
            except KeyboardInterrupt:
                return None
    
    def record_session(online, stream, device_idx=None, 
                      model_size="medium", chunk_duration=1.0, use_vac=False,
                      config_manager=None, perf_display=None, device_protector=None,
                      input_language="auto", use_async_output=True, translation_manager=None):
        """æ‰§è¡Œä¸€æ¬¡å½•éŸ³ä¼šè¯ï¼ˆæ”¯æŒç¿»è¯‘åŠŸèƒ½ï¼‰
        
        Args:
            online: ASRå¤„ç†å™¨å¯¹è±¡
            stream: å·²æ‰“å¼€çš„éŸ³é¢‘æµå¯¹è±¡ï¼ˆä¸å†åœ¨å‡½æ•°å†…éƒ¨æ‰“å¼€/å…³é—­ï¼‰
            device_idx: è®¾å¤‡ç´¢å¼•ï¼ˆå¯é€‰ï¼Œç”¨äºé¦–æ¬¡é€‰æ‹©è®¾å¤‡ï¼‰
            model_size: æ¨¡å‹å¤§å°
            chunk_duration: å¤„ç†é—´éš”
            use_vac: æ˜¯å¦ä½¿ç”¨VACæ¨¡å¼
            use_async_output: æ˜¯å¦ä½¿ç”¨å¼‚æ­¥è¾“å‡ºï¼ˆé¿å…è¾“å‡ºé˜»å¡ä¸»å¾ªç¯ï¼‰
        """
        # å¯åŠ¨å¼‚æ­¥è¾“å‡ºï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if use_async_output:
            _async_output.start()
        
        try:
            # é‡æ–°åˆå§‹åŒ–å¤„ç†å™¨
            online.init()
        except Exception as e:
            error_msg = f"ASRå¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}"
            if perf_display:
                perf_display.display_error("åˆå§‹åŒ–å¤±è´¥", error_msg, "è¯·æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ­£ç¡®åŠ è½½")
            else:
                print(f"âœ— {error_msg}")
            return False
        
        # è¯´è¯å¯†é›†ç¨‹åº¦æ£€æµ‹ï¼ˆç”¨äºåŠ¨æ€è°ƒæ•´é™éŸ³æ£€æµ‹æ—¶é—´ï¼‰
        recognition_times = []  # è®°å½•æœ€è¿‘å‡ æ¬¡è¯†åˆ«ç»“æœçš„æ—¶é—´æˆ³
        last_silence_adjustment_time = time.time()  # ä¸Šæ¬¡è°ƒæ•´é™éŸ³æ£€æµ‹æ—¶é—´çš„æ—¶é—´
        silence_adjustment_interval = 2.0  # æ¯2ç§’æ£€æŸ¥ä¸€æ¬¡æ˜¯å¦éœ€è¦è°ƒæ•´
        
        # è°ƒè¯•ï¼šç¡®è®¤è¿›å…¥ä¸»å¾ªç¯
        try:
            # è®¡ç®—è¯»å–å—å¤§å°ï¼ˆä¸å†æ‰“å¼€éŸ³é¢‘æµï¼Œä½¿ç”¨ä¼ å…¥çš„streamï¼‰
            if use_vac:
                read_chunk_size = int(0.04 * SAMPLING_RATE)  # VAC æ¨èï¼š0.04 ç§’ï¼ˆ512 æ ·æœ¬ï¼‰
            elif model_size in ['large-v2', 'large-v3', 'large']:
                read_chunk_size = int(0.5 * SAMPLING_RATE)  # å¤§æ¨¡å‹ï¼šæ¯æ¬¡è¯»å– 0.5 ç§’
            else:
                read_chunk_size = int(0.3 * SAMPLING_RATE)  # ä¸­å°æ¨¡å‹ï¼šæ¯æ¬¡è¯»å– 0.3 ç§’
            
            # ä½¿ç”¨ä¼ å…¥çš„streamï¼Œä¸å†ä½¿ç”¨withè¯­å¥
            if stream is None:
                if perf_display:
                    perf_display.display_error("éŸ³é¢‘æµé”™è¯¯", "éŸ³é¢‘æµæœªæ‰“å¼€", "è¯·é‡æ–°å¯åŠ¨ç¨‹åº")
                else:
                    print("âš  é”™è¯¯ï¼šéŸ³é¢‘æµæœªæ‰“å¼€")
                return False
            
            # åˆå§‹åŒ–ä¼šè¯å˜é‡
            last_process_time = time.time()
            last_activity_time = time.time()
            last_heartbeat_time = time.time()
            no_audio_warning_shown = False
            
            # åˆå§‹åŒ–è·³å¥æ—¥å¿—è®°å½•å™¨
            skip_logger = logging.getLogger('SkipLogger')
            skip_logger.setLevel(logging.INFO)
            
            # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦è¾“å‡ºåˆ°æ§åˆ¶å°
            console_log_enabled = True  # é»˜è®¤å¯ç”¨
            if config_manager:
                console_log_enabled = config_manager.get("logging.console_log_enabled", True)
            
            # å¦‚æœå·²æœ‰handlersï¼Œéœ€è¦æ ¹æ®é…ç½®é‡æ–°é…ç½®ï¼ˆç‰¹åˆ«æ˜¯æ§åˆ¶å°è¾“å‡ºï¼‰
            if skip_logger.handlers:
                # ç§»é™¤æ‰€æœ‰ç°æœ‰çš„æ§åˆ¶å°handlerï¼ˆStreamHandlerï¼‰
                handlers_to_remove = [h for h in skip_logger.handlers if isinstance(h, logging.StreamHandler) and not isinstance(h, logging.FileHandler)]
                for handler in handlers_to_remove:
                    skip_logger.removeHandler(handler)
                    handler.close()
            
            # é¿å…é‡å¤æ·»åŠ handlerï¼ˆåªåœ¨æ²¡æœ‰handleræ—¶æ·»åŠ ï¼‰
            if not skip_logger.handlers:
                formatter = logging.Formatter(
                    '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
                    datefmt='%Y-%m-%d %H:%M:%S'
                )
                
                # æ§åˆ¶å°è¾“å‡ºï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if console_log_enabled:
                    console_handler = logging.StreamHandler()
                    console_handler.setFormatter(formatter)
                    skip_logger.addHandler(console_handler)
                
                # æ–‡ä»¶è¾“å‡ºï¼ˆä¿å­˜åˆ°logsç›®å½•ï¼‰
                log_dir = "logs"
                os.makedirs(log_dir, exist_ok=True)
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                log_file = os.path.join(log_dir, f"skip_{timestamp}.log")
                file_handler = logging.FileHandler(log_file, encoding='utf-8')
                file_handler.setFormatter(formatter)
                skip_logger.addHandler(file_handler)
                skip_logger.info(f"è·³å¥æ—¥å¿—å·²å¯ç”¨ï¼Œæ—¥å¿—æ–‡ä»¶: {log_file}")
            else:
                # å¦‚æœå·²æœ‰handlersï¼Œåªæ·»åŠ æ§åˆ¶å°handlerï¼ˆå¦‚æœéœ€è¦ï¼‰
                if console_log_enabled:
                    # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ§åˆ¶å°handler
                    has_console = any(isinstance(h, logging.StreamHandler) and not isinstance(h, logging.FileHandler) 
                                     for h in skip_logger.handlers)
                    if not has_console:
                        formatter = logging.Formatter(
                            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
                            datefmt='%Y-%m-%d %H:%M:%S'
                        )
                        console_handler = logging.StreamHandler()
                        console_handler.setFormatter(formatter)
                        skip_logger.addHandler(console_handler)
            
            # ä¼šè¯å¼€å§‹æç¤ºå·²åœ¨ä¸»å¾ªç¯ä¸­æ˜¾ç¤ºï¼Œè¿™é‡Œä¸éœ€è¦é‡å¤æ˜¾ç¤º
            
            # åˆå§‹åŒ–æ”¹è¿›çš„è·³å¥æ£€æµ‹å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            skip_detector = None
            if SKIP_DETECTOR_AVAILABLE:
                # æ ¹æ®è¯­è¨€è·å–ç‰¹å®šé…ç½®
                if config_manager:
                    skip_config = config_manager.get_language_specific_config(
                        input_language, "skip_detector"
                    )
                    skip_detector = ImprovedSkipDetector(
                        similarity_threshold=skip_config.get("similarity_threshold", 0.85),
                        time_window=skip_config.get("time_window", 3.0),
                        min_length=skip_config.get("min_length", 2),
                        use_edit_distance=skip_config.get("use_edit_distance", True)
                    )
                else:
                    # æ²¡æœ‰é…ç½®ç®¡ç†å™¨ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    skip_detector = ImprovedSkipDetector(
                        similarity_threshold=0.85,
                        time_window=3.0,
                        min_length=2,
                        use_edit_distance=True
                    )
            
            # åˆå§‹åŒ–éŸ³é¢‘çº§åˆ«å»é‡å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            audio_deduplicator = None
            if AUDIO_DEDUPLICATOR_AVAILABLE and config_manager:
                dedup_config = config_manager.get("audio_deduplication", {})
                if dedup_config.get("enable", False):
                    try:
                        audio_deduplicator = AudioDeduplicator(
                            similarity_threshold=dedup_config.get("similarity_threshold", 0.95),
                            time_window=dedup_config.get("time_window", 3.0),
                            min_audio_length=dedup_config.get("min_audio_length", 0.1),
                            enable=True
                        )
                        if perf_display:
                            perf_display.set_audio_deduplicator(audio_deduplicator)
                            perf_display.display_info("éŸ³é¢‘å»é‡å·²å¯ç”¨ï¼šå°†åœ¨è¯†åˆ«å‰è¿‡æ»¤é‡å¤éŸ³é¢‘")
                    except Exception as e:
                        # éŸ³é¢‘å»é‡å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œä¸å½±å“ä¸»ç¨‹åºè¿è¡Œ
                        if perf_display:
                            perf_display.display_warning(f"éŸ³é¢‘å»é‡åˆå§‹åŒ–å¤±è´¥: {e}")
                        else:
                            print(f"âš  éŸ³é¢‘å»é‡åˆå§‹åŒ–å¤±è´¥: {e}")
                        audio_deduplicator = None
            
            # åˆå§‹åŒ–äººå£°åˆ†ç¦»å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            vocal_separator = None
            if VOCAL_SEPARATION_AVAILABLE and config_manager:
                sep_config = config_manager.get("vocal_separation", {})
                if sep_config.get("enable", False):
                    method = sep_config.get("method", "demucs")
                    if method.lower() != "none":
                        try:
                            if method.lower() == "demucs":
                                model_name = sep_config.get("demucs_model", "htdemucs")
                                model_path = sep_config.get("demucs_model_path", "")
                                # å¦‚æœè·¯å¾„ä¸ºç©ºå­—ç¬¦ä¸²ï¼Œåˆ™ä½¿ç”¨Noneï¼ˆä½¿ç”¨é»˜è®¤è·¯å¾„ï¼‰
                                model_path = model_path if model_path and model_path.strip() else None
                                vocal_separator = create_separator("demucs", SAMPLING_RATE, 
                                                                   model_name=model_name, 
                                                                   model_path=model_path)
                            elif method.lower() == "spleeter":
                                model_type = sep_config.get("spleeter_model", "2stems")
                                vocal_separator = create_separator("spleeter", SAMPLING_RATE, model_type=model_type)
                            elif method.lower() == "filter":
                                low_cut = sep_config.get("filter_low_cut", 85.0)
                                high_cut = sep_config.get("filter_high_cut", 3400.0)
                                vocal_separator = create_separator("filter", SAMPLING_RATE, low_cut=low_cut, high_cut=high_cut)
                            
                            if vocal_separator and vocal_separator.is_available():
                                if perf_display:
                                    perf_display.display_success(f"äººå£°åˆ†ç¦»å·²å¯ç”¨: {method}")
                                else:
                                    print(f"âœ“ äººå£°åˆ†ç¦»å·²å¯ç”¨: {method}")
                        except Exception as e:
                            if perf_display:
                                perf_display.display_warning(f"äººå£°åˆ†ç¦»åˆå§‹åŒ–å¤±è´¥: {e}")
                            else:
                                print(f"âš  äººå£°åˆ†ç¦»åˆå§‹åŒ–å¤±è´¥: {e}")
                            vocal_separator = None
            
            if use_vac:
                # VAC æ¨¡å¼ï¼šç®€åŒ–é€»è¾‘ï¼ŒVAC ä¼šè‡ªåŠ¨å¤„ç†è¯­éŸ³æ´»åŠ¨æ£€æµ‹
                # åªéœ€è¦æŒç»­è¯»å–éŸ³é¢‘å¹¶æ’å…¥ï¼ŒVAC ä¼šåœ¨æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸæ—¶è‡ªåŠ¨å¤„ç†
                last_recognized_text = ""  # ç”¨äºå»é‡ï¼ˆå…¼å®¹æ—§ä»£ç ï¼‰
                # print(f"[DEBUG] è¿›å…¥VACæ¨¡å¼ä¸»å¾ªç¯", flush=True)
                # loop_count = 0
                while True:
                    # loop_count += 1
                    # if loop_count % 100 == 0:  # æ¯100æ¬¡å¾ªç¯è¾“å‡ºä¸€æ¬¡ï¼Œé¿å…åˆ·å±
                    #     print(f"[DEBUG] ä¸»å¾ªç¯è¿è¡Œä¸­... (å·²å¾ªç¯ {loop_count} æ¬¡)", flush=True)
                    
                    try:
                        # ä»éº¦å…‹é£è¯»å–éŸ³é¢‘
                        audio_chunk, overflowed = stream.read(read_chunk_size)
                        audio_chunk = audio_chunk.flatten()
                        
                        if overflowed:
                            print("âš  éŸ³é¢‘ç¼“å†²åŒºæº¢å‡º", end='\r')
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰å®é™…éŸ³é¢‘æ•°æ®
                        if np.any(np.abs(audio_chunk) > 1e-6):
                            last_activity_time = time.time()
                            no_audio_warning_shown = False
                        else:
                            if time.time() - last_activity_time > 5 and not no_audio_warning_shown:
                                # æ˜¾ç¤ºçŠ¶æ€æç¤º
                                print("âš  æ£€æµ‹åˆ°é•¿æ—¶é—´æ— éŸ³é¢‘è¾“å…¥ï¼Œè¯·æ£€æŸ¥éº¦å…‹é£...", end='\r')
                                no_audio_warning_shown = True
                        
                        # äººå£°åˆ†ç¦»ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                        if vocal_separator and vocal_separator.is_available():
                            try:
                                # åˆ†ç¦»äººå£°å’ŒèƒŒæ™¯éŸ³ä¹
                                vocal_audio, _ = vocal_separator.separate(audio_chunk)
                                # ä½¿ç”¨åˆ†ç¦»åçš„äººå£°éŸ³é¢‘
                                audio_chunk = vocal_audio
                            except Exception as e:
                                # åˆ†ç¦»å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹éŸ³é¢‘
                                pass
                        
                        # éŸ³é¢‘çº§åˆ«å»é‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰- åœ¨è¿›å…¥ASRæ¨¡å‹ä¹‹å‰æ£€æµ‹é‡å¤éŸ³é¢‘
                        should_skip_audio = False
                        if audio_deduplicator:
                            try:
                                skip_audio, skip_reason, skip_details = audio_deduplicator.should_skip(
                                    audio_chunk, 
                                    sample_rate=SAMPLING_RATE,
                                    current_time=time.time()
                                )
                                if skip_audio:
                                    should_skip_audio = True
                                    # è·³è¿‡æ­¤éŸ³é¢‘å—ï¼Œä¸å‘é€åˆ°ASRæ¨¡å‹
                                    # å¯é€‰ï¼šè®°å½•æ—¥å¿—ï¼ˆä½†ä¸ºäº†æ€§èƒ½ï¼Œè¿™é‡Œä¸è®°å½•ï¼‰
                                    continue
                            except Exception as e:
                                # å»é‡æ£€æµ‹å¤±è´¥ï¼Œç»§ç»­å¤„ç†ï¼ˆä¿å®ˆç­–ç•¥ï¼‰
                                pass
                        
                        # ç›´æ¥æ’å…¥éŸ³é¢‘ï¼ŒVAC ä¼šè‡ªåŠ¨æ£€æµ‹è¯­éŸ³æ´»åŠ¨
                        # VAC ä¼šåœ¨æ£€æµ‹åˆ° 500ms é™éŸ³æ—¶è‡ªåŠ¨è§¦å‘å¤„ç†
                        online.insert_audio_chunk(audio_chunk)
                        
                        current_time = time.time()
                        
                        # å®šæœŸè°ƒç”¨ process_iterï¼ˆVAC æ¨¡å¼ä¸‹ï¼Œå®ƒä¼šåœ¨æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸæ—¶è¿”å›ç»“æœï¼‰
                        has_result = False
                        if (current_time - last_process_time) >= 0.5:  # æ¯ 0.5 ç§’æ£€æŸ¥ä¸€æ¬¡
                            # print(f"[DEBUG] è°ƒç”¨ process_iter()...", flush=True)
                            try:
                                result = online.process_iter()
                                
                                # è¾“å‡ºç»“æœï¼ˆVAC ä¼šåœ¨æ£€æµ‹åˆ°å¥å­ç»“æŸæ—¶è¿”å›ç»“æœï¼‰
                                if result[0] is not None:
                                    # æœ‰è¯†åˆ«ç»“æœï¼Œæ¸…é™¤nonvoiceæç¤º
                                    print("\r" + " " * 50 + "\r", end='', flush=True)
                                    has_result = True
                                    
                                    beg_time, end_time, text = result
                                    # éªŒè¯æ—¶é—´æˆ³æœ‰æ•ˆæ€§ï¼ˆé¿å…æ—¶é—´æˆ³å¼‚å¸¸å¯¼è‡´çš„é—®é¢˜ï¼‰
                                    # æ³¨æ„ï¼šend_time == beg_time å¯èƒ½æ˜¯æ­£å¸¸çš„æçŸ­ç‰‡æ®µï¼ˆå¦‚å•å­—ï¼‰ï¼Œå…è®¸é€šè¿‡
                                    if end_time < beg_time:
                                        # æ—¶é—´æˆ³å¼‚å¸¸ï¼ˆç»“æŸæ—¶é—´å°äºå¼€å§‹æ—¶é—´ï¼‰ï¼Œè·³è¿‡æ­¤æ¬¡ç»“æœ
                                        if perf_display:
                                            perf_display.display_warning(f"æ—¶é—´æˆ³å¼‚å¸¸: {beg_time:.2f}s-{end_time:.2f}sï¼Œå·²è·³è¿‡")
                                        else:
                                            print(f"âš  æ—¶é—´æˆ³å¼‚å¸¸: {beg_time:.2f}s-{end_time:.2f}sï¼Œå·²è·³è¿‡")
                                        last_process_time = current_time
                                        continue
                                    
                                    # å¦‚æœæ—¶é—´æˆ³ç›¸ç­‰ï¼Œæ£€æŸ¥æ–‡æœ¬é•¿åº¦ï¼Œå¦‚æœæ–‡æœ¬è¿‡é•¿å¯èƒ½æ˜¯å¼‚å¸¸
                                    if end_time == beg_time and text and len(text.strip()) > 50:
                                        # æ—¶é—´æˆ³ç›¸ç­‰ä½†æ–‡æœ¬å¾ˆé•¿ï¼Œå¯èƒ½æ˜¯å¼‚å¸¸ï¼Œè·³è¿‡
                                        if perf_display:
                                            perf_display.display_warning(f"æ—¶é—´æˆ³å¼‚å¸¸: {beg_time:.2f}s (æ–‡æœ¬è¿‡é•¿:{len(text.strip())}å­—)ï¼Œå·²è·³è¿‡")
                                        else:
                                            print(f"âš  æ—¶é—´æˆ³å¼‚å¸¸: {beg_time:.2f}s (æ–‡æœ¬è¿‡é•¿:{len(text.strip())}å­—)ï¼Œå·²è·³è¿‡")
                                        last_process_time = current_time
                                        continue
                                    
                                    if text and text.strip():
                                        text_clean = text.strip()
                                        
                                        # ä½¿ç”¨æ”¹è¿›çš„è·³å¥æ£€æµ‹å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                                        should_skip = False
                                        skip_reason = None
                                        skip_details = None
                                        
                                        if skip_detector is not None:
                                            should_skip, skip_reason, skip_details = skip_detector.should_skip(text_clean, current_time)
                                            
                                            if should_skip:
                                                # è®°å½•è·³å¥æ—¥å¿—
                                                if skip_details:
                                                    details_str = ', '.join([f"{k}={v}" if not isinstance(v, float) else f"{k}={v:.3f}" 
                                                                           for k, v in skip_details.items() if k != 'type'])
                                                    skip_logger.info(f"[è·³å¥-recognition] åŸå› : {skip_reason}, è¯¦æƒ…: {details_str}, æ—¶é—´: {beg_time:.2f}-{end_time:.2f}s")
                                                else:
                                                    skip_logger.info(f"[è·³å¥-recognition] åŸå› : {skip_reason}, æ—¶é—´: {beg_time:.2f}-{end_time:.2f}s")
                                                last_process_time = current_time
                                                continue
                                        else:
                                            # å›é€€åˆ°åŸºç¡€å»é‡é€»è¾‘
                                            if text_clean == last_recognized_text or \
                                               (last_recognized_text and text_clean in last_recognized_text and len(text_clean) < len(last_recognized_text)):
                                                # è¿™æ˜¯é‡å¤æˆ–éƒ¨åˆ†ç»“æœï¼Œè·³è¿‡
                                                # è®°å½•è·³å¥æ—¥å¿—
                                                if text_clean == last_recognized_text:
                                                    skip_reason = "duplicate"
                                                    skip_details = f"å®Œå…¨é‡å¤: '{text_clean}' == '{last_recognized_text}'"
                                                else:
                                                    skip_reason = "partial"
                                                    skip_details = f"éƒ¨åˆ†é‡å¤: '{text_clean}' æ˜¯ '{last_recognized_text}' çš„ä¸€éƒ¨åˆ†"
                                                skip_logger.info(f"[è·³å¥-recognition] åŸå› : {skip_reason}, è¯¦æƒ…: {skip_details}, æ—¶é—´: {beg_time:.2f}-{end_time:.2f}s")
                                                last_process_time = current_time
                                                continue
                                        
                                        # æ›´æ–°æœ€åè¯†åˆ«çš„æ–‡æœ¬ï¼ˆå…¼å®¹æ—§ä»£ç ï¼‰
                                        last_recognized_text = text_clean
                                        
                                        # æœ‰è¯†åˆ«ç»“æœï¼Œæ¸…é™¤æ‰€æœ‰çŠ¶æ€æç¤º
                                        if use_async_output:
                                            _async_output.print_no_newline("\r" + " " * 100 + "\r")
                                        else:
                                            print("\r" + " " * 100 + "\r", end='', flush=True)
                                        
                                        # æ˜¾ç¤ºè¯†åˆ«ç»“æœï¼ˆä½¿ç”¨å¼‚æ­¥è¾“å‡ºé¿å…é˜»å¡ï¼‰
                                        if use_async_output:
                                            _async_output.print(f"ğŸ’¬ {text}")
                                        else:
                                            print(f"ğŸ’¬ {text}", flush=True)
                                        
                                        # å¦‚æœå¯ç”¨ç¿»è¯‘ï¼Œæ·»åŠ åˆ°ç¿»è¯‘é˜Ÿåˆ—
                                        if translation_manager is not None:
                                            translation_manager.add_text(text_clean)
                                        
                                        # è®°å½•è¯†åˆ«ç»“æœæ—¶é—´æˆ³ï¼ˆç”¨äºè¯´è¯å¯†é›†ç¨‹åº¦æ£€æµ‹ï¼‰
                                        recognition_times.append(current_time)
                                        # åªä¿ç•™æœ€è¿‘5æ¬¡è¯†åˆ«ç»“æœçš„æ—¶é—´æˆ³
                                        if len(recognition_times) > 5:
                                            recognition_times.pop(0)
                                        
                                        # å¼‚æ­¥flushï¼ˆå¦‚æœå¯ç”¨ï¼‰
                                        if use_async_output:
                                            _async_output.flush()
                                        else:
                                            sys.stdout.flush()
                                        last_activity_time = current_time
                                    
                                    last_process_time = current_time
                                    
                                    # åŠ¨æ€è°ƒæ•´é™éŸ³æ£€æµ‹æ—¶é—´ï¼ˆæ¯2ç§’æ£€æŸ¥ä¸€æ¬¡ï¼‰
                                    if use_vac and hasattr(online, 'set_silence_duration') and \
                                       (current_time - last_silence_adjustment_time) >= silence_adjustment_interval:
                                        if len(recognition_times) >= 2:
                                            # è®¡ç®—æœ€è¿‘å‡ æ¬¡è¯†åˆ«ç»“æœçš„å¹³å‡æ—¶é—´é—´éš”
                                            intervals = []
                                            for i in range(1, len(recognition_times)):
                                                intervals.append(recognition_times[i] - recognition_times[i-1])
                                            avg_interval = sum(intervals) / len(intervals) if intervals else 5.0
                                            
                                            # æ ¹æ®å¹³å‡æ—¶é—´é—´éš”è°ƒæ•´é™éŸ³æ£€æµ‹æ—¶é—´
                                            # é—´éš”çŸ­ï¼ˆ<2ç§’ï¼‰= å¯†é›†è¯´è¯ï¼Œç¼©çŸ­é™éŸ³æ£€æµ‹æ—¶é—´ï¼ˆ200-300msï¼‰
                                            # é—´éš”é•¿ï¼ˆ>5ç§’ï¼‰= ç¨€ç–è¯´è¯ï¼Œå»¶é•¿é™éŸ³æ£€æµ‹æ—¶é—´ï¼ˆ800-1000msï¼‰
                                            if avg_interval < 2.0:
                                                # å¯†é›†è¯´è¯ï¼šä½¿ç”¨è¾ƒçŸ­çš„é™éŸ³æ£€æµ‹æ—¶é—´
                                                new_silence_ms = int(200 + (avg_interval / 2.0) * 100)  # 200-300ms
                                            elif avg_interval > 5.0:
                                                # ç¨€ç–è¯´è¯ï¼šä½¿ç”¨è¾ƒé•¿çš„é™éŸ³æ£€æµ‹æ—¶é—´
                                                new_silence_ms = int(600 + min((avg_interval - 5.0) / 5.0, 1.0) * 400)  # 600-1000ms
                                            else:
                                                # ä¸­ç­‰å¯†åº¦ï¼šä½¿ç”¨ä¸­ç­‰é™éŸ³æ£€æµ‹æ—¶é—´
                                                new_silence_ms = int(300 + (avg_interval - 2.0) / 3.0 * 300)  # 300-600ms
                                            
                                            # åº”ç”¨è°ƒæ•´
                                            if online.set_silence_duration(new_silence_ms):
                                                # åªåœ¨æˆåŠŸè°ƒæ•´æ—¶æ›´æ–°æ—¶é—´å’Œè¾“å‡ºæç¤º
                                                last_silence_adjustment_time = current_time
                                                # å¯é€‰ï¼šè¾“å‡ºè°ƒæ•´ä¿¡æ¯ï¼ˆè°ƒè¯•ç”¨ï¼Œå¯ä»¥æ³¨é‡Šæ‰ï¼‰
                                                # print(f"\r[é™éŸ³æ£€æµ‹: {new_silence_ms}ms (é—´éš”: {avg_interval:.1f}s)]", end='', flush=True)
                                        else:
                                            last_silence_adjustment_time = current_time
                            except Exception as e:
                                print(f"\nâš  å¤„ç†é”™è¯¯: {e}")
                                print("ç»§ç»­å½•éŸ³ä¸­...")
                                sys.stdout.flush()
                                last_process_time = current_time
                        
                        # å¦‚æœæ²¡æœ‰è¯†åˆ«ç»“æœï¼Œæ˜¾ç¤ºnonvoiceé—ªçƒæç¤ºï¼ˆæ¯0.2ç§’æ›´æ–°ä¸€æ¬¡ï¼Œå®ç°æµç•…é—ªçƒï¼‰
                        # å¦‚æœæ²¡æœ‰è¯†åˆ«ç»“æœï¼Œæ˜¾ç¤ºnonvoiceé—ªçƒæç¤º
                        if not has_result and (current_time - last_process_time) >= 0.2:
                            # ä½¿ç”¨æ—¶é—´æˆ³åˆ›å»ºé—ªçƒæ•ˆæœï¼ˆæ¯0.5ç§’åˆ‡æ¢ä¸€æ¬¡ï¼‰
                            blink_state = int(current_time * 2) % 2
                            if blink_state == 0:
                                print("\rğŸ”‡ nonvoice", end='', flush=True)
                            else:
                                print("\r   nonvoice", end='', flush=True)
                    
                    except sd.PortAudioError as e:
                        print(f"\nâœ— éŸ³é¢‘æµé”™è¯¯: {e}")
                        raise
                    except Exception as e:
                        print(f"\nâš  è¯»å–éŸ³é¢‘æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                        time.sleep(0.1)
                        continue
                    
                    # å¿ƒè·³æ£€æµ‹
                    current_time = time.time()
                    if current_time - last_heartbeat_time > 10:
                        if current_time - last_activity_time < 2:
                            last_heartbeat_time = current_time
                        else:
                            # æ˜¾ç¤ºçŠ¶æ€æç¤º
                            print("â³ å½•éŸ³ä¸­... (ç­‰å¾…è¯­éŸ³è¾“å…¥)", end='\r')
                            last_heartbeat_time = current_time
            
            else:
                # é VAC æ¨¡å¼ï¼šä½¿ç”¨åŸæœ‰çš„ç¼“å†²å’Œå¤„ç†é€»è¾‘
                temp_buffer = np.array([], dtype=np.float32)
                min_buffer_size = int(chunk_duration * SAMPLING_RATE)
                last_recognized_text = ""  # ç”¨äºå»é‡ï¼ˆå…¼å®¹æ—§ä»£ç ï¼‰
                
                while True:
                    try:
                        # ä»éº¦å…‹é£è¯»å–éŸ³é¢‘ï¼ˆä½¿ç”¨è®¾å¤‡ä¿æŠ¤å™¨æˆ–ç›´æ¥è¯»å–ï¼‰
                        if device_protector is not None:
                            audio_chunk, overflowed, read_error = device_protector.read_audio(read_chunk_size)
                            if audio_chunk is None:
                                if read_error:
                                    if "è®¾å¤‡å·²æ¢å¤" in read_error:
                                        # è®¾å¤‡å·²æ¢å¤ï¼Œç»§ç»­ä¸‹ä¸€æ¬¡å¾ªç¯
                                        if perf_display:
                                            perf_display.display_success("éŸ³é¢‘è®¾å¤‡å·²æ¢å¤")
                                        continue
                                    else:
                                        # å°è¯•æ¢å¤
                                        if perf_display:
                                            perf_display.display_warning(f"è¯»å–éŸ³é¢‘å¤±è´¥: {read_error}")
                                            perf_display.display_progress("æ­£åœ¨å°è¯•æ¢å¤éŸ³é¢‘æµ...")
                                        success, new_stream, recover_error = device_protector.recover_stream(
                                            samplerate=SAMPLING_RATE,
                                            channels=1,
                                            blocksize=read_chunk_size,
                                            dtype='float32'
                                        )
                                        if success:
                                            stream = new_stream
                                            if perf_display:
                                                perf_display.clear()
                                                perf_display.display_success("éŸ³é¢‘æµå·²æ¢å¤ï¼Œç»§ç»­å½•éŸ³")
                                            continue
                                        else:
                                            if perf_display:
                                                perf_display.display_error(
                                                    "è®¾å¤‡æ¢å¤å¤±è´¥",
                                                    recover_error,
                                                    "è¯·æ£€æŸ¥éº¦å…‹é£æ˜¯å¦å·²è¿æ¥å¹¶å¯ç”¨"
                                                )
                                            raise sd.PortAudioError(recover_error)
                            audio_chunk = audio_chunk.flatten()
                        else:
                            audio_chunk, overflowed = stream.read(read_chunk_size)
                            audio_chunk = audio_chunk.flatten()
                        
                        if overflowed:
                            if perf_display:
                                perf_display.display_warning("éŸ³é¢‘ç¼“å†²åŒºæº¢å‡º")
                            else:
                                print("âš  éŸ³é¢‘ç¼“å†²åŒºæº¢å‡º", end='\r')
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰å®é™…éŸ³é¢‘æ•°æ®
                        if np.any(np.abs(audio_chunk) > 1e-6):
                            last_activity_time = time.time()
                            no_audio_warning_shown = False
                        else:
                            if time.time() - last_activity_time > 5 and not no_audio_warning_shown:
                                # æ˜¾ç¤ºçŠ¶æ€æç¤º
                                print("âš  æ£€æµ‹åˆ°é•¿æ—¶é—´æ— éŸ³é¢‘è¾“å…¥ï¼Œè¯·æ£€æŸ¥éº¦å…‹é£...", end='\r')
                                no_audio_warning_shown = True
                        
                        # ç´¯ç§¯åˆ°ä¸´æ—¶ç¼“å†²åŒº
                        temp_buffer = np.append(temp_buffer, audio_chunk)
                        
                        # æŒ‰å¤„ç†é—´éš”å®šæœŸå¤„ç†
                        current_time = time.time()
                        time_elapsed = current_time - last_process_time
                        
                        if (time_elapsed >= chunk_duration and len(temp_buffer) >= min_buffer_size) or \
                           (len(temp_buffer) >= min_buffer_size * 2):
                            
                            # éŸ³é¢‘çº§åˆ«å»é‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰- åœ¨è¿›å…¥ASRæ¨¡å‹ä¹‹å‰æ£€æµ‹é‡å¤éŸ³é¢‘
                            should_skip_audio = False
                            if audio_deduplicator:
                                try:
                                    skip_audio, skip_reason, skip_details = audio_deduplicator.should_skip(
                                        temp_buffer, 
                                        sample_rate=SAMPLING_RATE,
                                        current_time=current_time
                                    )
                                    if skip_audio:
                                        should_skip_audio = True
                                        # è·³è¿‡æ­¤éŸ³é¢‘å—ï¼Œä¸å‘é€åˆ°ASRæ¨¡å‹
                                        temp_buffer = np.array([], dtype=np.float32)
                                        last_process_time = current_time
                                        continue
                                except Exception as e:
                                    # å»é‡æ£€æµ‹å¤±è´¥ï¼Œç»§ç»­å¤„ç†ï¼ˆä¿å®ˆç­–ç•¥ï¼‰
                                    pass
                            
                            online.insert_audio_chunk(temp_buffer)
                            temp_buffer = np.array([], dtype=np.float32)
                            
                            try:
                                result = online.process_iter()
                                # if result[0] is not None:
                                #     beg_time, end_time, text = result
                                #     print(f"[DEBUG] process_iterè¿”å›ç»“æœ: text='{text}', é•¿åº¦={len(text) if text else 0}", flush=True)
                                
                                if result[0] is not None:
                                    beg_time, end_time, text = result
                                    # éªŒè¯æ—¶é—´æˆ³æœ‰æ•ˆæ€§ï¼ˆé¿å…æ—¶é—´æˆ³å¼‚å¸¸å¯¼è‡´çš„é—®é¢˜ï¼‰
                                    # æ³¨æ„ï¼šend_time == beg_time å¯èƒ½æ˜¯æ­£å¸¸çš„æçŸ­ç‰‡æ®µï¼ˆå¦‚å•å­—ï¼‰ï¼Œå…è®¸é€šè¿‡
                                    if end_time < beg_time:
                                        # æ—¶é—´æˆ³å¼‚å¸¸ï¼ˆç»“æŸæ—¶é—´å°äºå¼€å§‹æ—¶é—´ï¼‰ï¼Œè·³è¿‡æ­¤æ¬¡ç»“æœ
                                        if perf_display:
                                            perf_display.display_warning(f"æ—¶é—´æˆ³å¼‚å¸¸: {beg_time:.2f}s-{end_time:.2f}sï¼Œå·²è·³è¿‡")
                                        else:
                                            print(f"âš  æ—¶é—´æˆ³å¼‚å¸¸: {beg_time:.2f}s-{end_time:.2f}sï¼Œå·²è·³è¿‡")
                                        continue
                                    
                                    # å¦‚æœæ—¶é—´æˆ³ç›¸ç­‰ï¼Œæ£€æŸ¥æ–‡æœ¬é•¿åº¦ï¼Œå¦‚æœæ–‡æœ¬è¿‡é•¿å¯èƒ½æ˜¯å¼‚å¸¸
                                    if end_time == beg_time and text and len(text.strip()) > 50:
                                        # æ—¶é—´æˆ³ç›¸ç­‰ä½†æ–‡æœ¬å¾ˆé•¿ï¼Œå¯èƒ½æ˜¯å¼‚å¸¸ï¼Œè·³è¿‡
                                        if perf_display:
                                            perf_display.display_warning(f"æ—¶é—´æˆ³å¼‚å¸¸: {beg_time:.2f}s (æ–‡æœ¬è¿‡é•¿:{len(text.strip())}å­—)ï¼Œå·²è·³è¿‡")
                                        else:
                                            print(f"âš  æ—¶é—´æˆ³å¼‚å¸¸: {beg_time:.2f}s (æ–‡æœ¬è¿‡é•¿:{len(text.strip())}å­—)ï¼Œå·²è·³è¿‡")
                                        continue
                                    
                                    if text and text.strip():
                                        # éªŒè¯æ—¶é—´æˆ³æœ‰æ•ˆæ€§
                                        if end_time <= beg_time:
                                            # æ—¶é—´æˆ³å¼‚å¸¸ï¼Œè·³è¿‡æ­¤æ¬¡ç»“æœ
                                            print(f"âš  æ—¶é—´æˆ³å¼‚å¸¸: {beg_time:.2f}s-{end_time:.2f}sï¼Œå·²è·³è¿‡")
                                            continue
                                        
                                        text_clean = text.strip()
                                        
                                        # ä½¿ç”¨æ”¹è¿›çš„è·³å¥æ£€æµ‹å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                                        should_skip = False
                                        skip_reason = None
                                        skip_details = None
                                        
                                        if skip_detector is not None:
                                            should_skip, skip_reason, skip_details = skip_detector.should_skip(text_clean, current_time)
                                            
                                            if should_skip:
                                                # è®°å½•è·³å¥æ—¥å¿—
                                                if skip_details:
                                                    details_str = ', '.join([f"{k}={v}" if not isinstance(v, float) else f"{k}={v:.3f}" 
                                                                           for k, v in skip_details.items() if k != 'type'])
                                                    skip_logger.info(f"[è·³å¥-recognition] åŸå› : {skip_reason}, è¯¦æƒ…: {details_str}, æ—¶é—´: {beg_time:.2f}-{end_time:.2f}s")
                                                else:
                                                    skip_logger.info(f"[è·³å¥-recognition] åŸå› : {skip_reason}, æ—¶é—´: {beg_time:.2f}-{end_time:.2f}s")
                                                continue
                                        else:
                                            # å›é€€åˆ°åŸºç¡€å»é‡é€»è¾‘
                                            if text_clean == last_recognized_text or \
                                               (last_recognized_text and text_clean in last_recognized_text and len(text_clean) < len(last_recognized_text)):
                                                # è¿™æ˜¯é‡å¤æˆ–éƒ¨åˆ†ç»“æœï¼Œè·³è¿‡
                                                # è®°å½•è·³å¥æ—¥å¿—
                                                if text_clean == last_recognized_text:
                                                    skip_reason = "duplicate"
                                                    skip_details = f"å®Œå…¨é‡å¤: '{text_clean}' == '{last_recognized_text}'"
                                                else:
                                                    skip_reason = "partial"
                                                    skip_details = f"éƒ¨åˆ†é‡å¤: '{text_clean}' æ˜¯ '{last_recognized_text}' çš„ä¸€éƒ¨åˆ†"
                                                skip_logger.info(f"[è·³å¥-recognition] åŸå› : {skip_reason}, è¯¦æƒ…: {skip_details}, æ—¶é—´: {beg_time:.2f}-{end_time:.2f}s")
                                                continue
                                        
                                        # æ›´æ–°æœ€åè¯†åˆ«çš„æ–‡æœ¬ï¼ˆå…¼å®¹æ—§ä»£ç ï¼‰
                                        last_recognized_text = text_clean
                                        
                                        # æœ‰è¯†åˆ«ç»“æœï¼Œæ¸…é™¤æ‰€æœ‰çŠ¶æ€æç¤º
                                        print("\r" + " " * 100 + "\r", end='', flush=True)
                                        
                                        # æ˜¾ç¤ºè¯†åˆ«ç»“æœ
                                        print(f"ğŸ’¬ {text}", flush=True)
                                        
                                        sys.stdout.flush()
                                        last_activity_time = current_time
                            except Exception as e:
                                print(f"\nâš  å¤„ç†é”™è¯¯: {e}")
                                print("ç»§ç»­å½•éŸ³ä¸­...")
                                sys.stdout.flush()
                            
                            last_process_time = current_time
                    
                    except sd.PortAudioError as e:
                        print(f"\nâœ— éŸ³é¢‘æµé”™è¯¯: {e}")
                        raise
                    except Exception as e:
                        print(f"\nâš  è¯»å–éŸ³é¢‘æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                        time.sleep(0.1)
                        continue
                    
                    # å¿ƒè·³æ£€æµ‹
                    current_time = time.time()
                    if current_time - last_heartbeat_time > 10:
                        if current_time - last_activity_time < 2:
                            last_heartbeat_time = current_time
                        else:
                            print("â³ å½•éŸ³ä¸­... (ç­‰å¾…éŸ³é¢‘è¾“å…¥)", end='\r')
                            last_heartbeat_time = current_time
                    
        except KeyboardInterrupt:
            print()
            print("\næ­£åœ¨åœæ­¢å½“å‰ä¼šè¯...")
            
            # ç¿»è¯‘åŠŸèƒ½å·²ç§»é™¤ï¼Œæ— éœ€æ¸…ç†
            
            # whisper_streaming å†…éƒ¨å·²ç»ç®¡ç†äº†æ‰€æœ‰éŸ³é¢‘ï¼Œç›´æ¥è°ƒç”¨ finish å³å¯
            # è·å–æœ€åçš„ç»“æœ
            try:
                final_result = online.finish()
                if final_result[0] is not None:
                    beg_time, end_time, text = final_result
                    # éªŒè¯æ—¶é—´æˆ³æœ‰æ•ˆæ€§
                    if end_time > beg_time and text.strip():
                        # æœ‰è¯†åˆ«ç»“æœï¼Œæ¸…é™¤æ‰€æœ‰çŠ¶æ€æç¤º
                        print("\r" + " " * 100 + "\r", end='', flush=True)
                        
                        # æ˜¾ç¤ºè¯†åˆ«ç»“æœ
                        print(f"ğŸ’¬ {text}")
            except:
                pass
            
            print("âœ“ å½“å‰ä¼šè¯å·²åœæ­¢")
            return True
        
        except sd.PortAudioError as e:
            print(f"\nâœ— éŸ³é¢‘è®¾å¤‡é”™è¯¯: {e}")
            print("æç¤º: è¯·æ£€æŸ¥éº¦å…‹é£æ˜¯å¦å·²è¿æ¥å¹¶å¯ç”¨")
            # whisper_streaming å†…éƒ¨å·²ç»ç®¡ç†äº†æ‰€æœ‰éŸ³é¢‘ï¼Œç›´æ¥è°ƒç”¨ finish å³å¯
            try:
                final_result = online.finish()
                if final_result[0] is not None:
                    beg_time, end_time, text = final_result
                    # éªŒè¯æ—¶é—´æˆ³æœ‰æ•ˆæ€§ï¼ˆå…è®¸ç›¸ç­‰ï¼Œä½†æ£€æŸ¥æ–‡æœ¬é•¿åº¦ï¼‰
                    if end_time >= beg_time and text.strip():
                        # å¦‚æœæ—¶é—´æˆ³ç›¸ç­‰ä½†æ–‡æœ¬è¿‡é•¿ï¼Œå¯èƒ½æ˜¯å¼‚å¸¸
                        if end_time == beg_time and len(text.strip()) > 50:
                            # è·³è¿‡å¼‚å¸¸çš„é•¿æ–‡æœ¬
                            pass
                        else:
                            # æœ‰è¯†åˆ«ç»“æœï¼Œæ¸…é™¤æ‰€æœ‰çŠ¶æ€æç¤º
                            print("\r" + " " * 100 + "\r", end='', flush=True)
                            
                            # æ˜¾ç¤ºè¯†åˆ«ç»“æœ
                            print(f"ğŸ’¬ {text}")
            except:
                pass
            return False
        except KeyboardInterrupt:
            # ç”¨æˆ·ä¸­æ–­ï¼Œæ­£å¸¸é€€å‡º
            print("\n\nç”¨æˆ·ä¸­æ–­å½•éŸ³")
            return False
        except Exception as e:
            error_msg = f"å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {e}"
            print(f"\nâœ— {error_msg}")
            import traceback
            traceback.print_exc()
            
            # å°è¯•æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
            if perf_display:
                perf_display.display_error("å½•éŸ³ä¼šè¯é”™è¯¯", str(e), "è¯·æ£€æŸ¥æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯")
            
            # whisper_streaming å†…éƒ¨å·²ç»ç®¡ç†äº†æ‰€æœ‰éŸ³é¢‘ï¼Œç›´æ¥è°ƒç”¨ finish å³å¯
            try:
                final_result = online.finish()
                if final_result[0] is not None:
                    beg_time, end_time, text = final_result
                    # éªŒè¯æ—¶é—´æˆ³æœ‰æ•ˆæ€§ï¼ˆå…è®¸ç›¸ç­‰ï¼Œä½†æ£€æŸ¥æ–‡æœ¬é•¿åº¦ï¼‰
                    if end_time >= beg_time and text.strip():
                        # å¦‚æœæ—¶é—´æˆ³ç›¸ç­‰ä½†æ–‡æœ¬è¿‡é•¿ï¼Œå¯èƒ½æ˜¯å¼‚å¸¸
                        if end_time == beg_time and len(text.strip()) > 50:
                            # è·³è¿‡å¼‚å¸¸çš„é•¿æ–‡æœ¬
                            pass
                        else:
                            # æœ‰è¯†åˆ«ç»“æœï¼Œæ¸…é™¤æ‰€æœ‰çŠ¶æ€æç¤º
                            print("\r" + " " * 100 + "\r", end='', flush=True)
                            
                            # æ˜¾ç¤ºè¯†åˆ«ç»“æœ
                            print(f"ğŸ’¬ {text}")
            except:
                pass
            return False
    
    # åˆ›å»ºåœ¨çº¿å¤„ç†å¯¹è±¡ï¼ˆåªéœ€è¦åˆ›å»ºä¸€æ¬¡ï¼‰
    # æ ¹æ®é…ç½®é€‰æ‹©ä½¿ç”¨ VAC æˆ–æ™®é€šå¤„ç†å™¨
    if use_vac:
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰ torchï¼ˆVAC éœ€è¦ï¼‰
            import torch
            print("æ­£åœ¨åˆå§‹åŒ– VAC (è¯­éŸ³æ´»åŠ¨æ£€æµ‹)...")
            
            # åˆ›å»ºè¿‡æ»¤logfileï¼Œè¿‡æ»¤æ‰"no online update, only VAD"æ¶ˆæ¯
            class FilteredLogFile:
                def __init__(self, original_file):
                    self.original_file = original_file
                
                def write(self, text):
                    # å®Œå…¨è¿‡æ»¤æ‰æ‰€æœ‰è¾“å‡ºï¼Œå› ä¸ºæˆ‘ä»¬åœ¨ä¸»å¾ªç¯ä¸­è‡ªå·±å¤„ç†çŠ¶æ€æ˜¾ç¤º
                    pass
                
                def flush(self):
                    self.original_file.flush()
            
            filtered_logfile = FilteredLogFile(sys.stderr)
            
            # å°è¯•ä½¿ç”¨å¢å¼ºçš„å¤„ç†å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            try:
                from enhanced_asr_processor import EnhancedVACOnlineASRProcessor
                # ä½¿ç”¨å¢å¼ºçš„VACå¤„ç†å™¨ï¼ˆæ”¯æŒ Local Agreement-nã€åŠ¨æ€ç¼“å†²åŒºç­‰ï¼‰
                online = EnhancedVACOnlineASRProcessor(
                    online_chunk_size=vac_chunk_size,
                    asr=asr,
                    tokenizer=None,  # ä½¿ç”¨ segment æ¨¡å¼ï¼Œä¸éœ€è¦ tokenizer
                    logfile=filtered_logfile,
                    buffer_trimming=("segment", 15),  # ç¼“å†²åŒºä¿®å‰ªï¼šsegment æ¨¡å¼ï¼Œ15ç§’é˜ˆå€¼
                    agreement_n=agreement_n,  # Local Agreement-nï¼ˆä»é…ç½®è¯»å–ï¼‰
                    enable_dynamic_buffer=True,  # å¯ç”¨åŠ¨æ€ç¼“å†²åŒºç®¡ç†
                    initial_silence_ms=vad_initial_silence_ms,  # åˆå§‹é™éŸ³æ£€æµ‹æ—¶é—´ï¼ˆä»é…ç½®è¯»å–ï¼‰
                    min_silence_ms=vad_min_silence_ms,  # æœ€å°é™éŸ³æ£€æµ‹æ—¶é—´ï¼ˆä»é…ç½®è¯»å–ï¼‰
                    max_silence_ms=vad_max_silence_ms,  # æœ€å¤§é™éŸ³æ£€æµ‹æ—¶é—´ï¼ˆä»é…ç½®è¯»å–ï¼‰
                    vad_threshold=vad_threshold  # VADé˜ˆå€¼ï¼ˆä»é…ç½®è¯»å–ï¼‰
                )
                print("âœ“ å¢å¼º VAC å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
                print(f"  - æ”¯æŒ Local Agreement-{agreement_n} ç­–ç•¥")
                print(f"  - VADé™éŸ³æ£€æµ‹: {vad_min_silence_ms}-{vad_max_silence_ms}ms")
                print(f"  - éŸ³é¢‘å—å¤§å°: {vac_chunk_size}ç§’")
                print("  - æ”¯æŒåŠ¨æ€ç¼“å†²åŒºç®¡ç†")
                print("  - ä¼˜åŒ–çš„ Init Prompt æå–")
            except ImportError:
                # å›é€€åˆ°åŸç‰ˆåŠ¨æ€VACå¤„ç†å™¨
                online = DynamicVACOnlineASRProcessor(
                vac_chunk_size,  # VAC éŸ³é¢‘å—å¤§å°
                asr,
                tokenizer=None,  # ä½¿ç”¨ segment æ¨¡å¼ï¼Œä¸éœ€è¦ tokenizer
                logfile=filtered_logfile,
                    buffer_trimming=("segment", 15),  # ç¼“å†²åŒºä¿®å‰ªï¼šsegment æ¨¡å¼ï¼Œ15ç§’é˜ˆå€¼
                    initial_silence_ms=500,  # åˆå§‹é™éŸ³æ£€æµ‹æ—¶é—´
                    min_silence_ms=200,  # æœ€å°é™éŸ³æ£€æµ‹æ—¶é—´ï¼ˆå¯†é›†è¯´è¯æ—¶ï¼‰
                    max_silence_ms=1000  # æœ€å¤§é™éŸ³æ£€æµ‹æ—¶é—´ï¼ˆç¨€ç–è¯´è¯æ—¶ï¼‰
            )
                print("âœ“ VAC åˆå§‹åŒ–æˆåŠŸï¼ˆæ”¯æŒåŠ¨æ€è°ƒæ•´ï¼‰")
            print("âœ“ VAC åˆå§‹åŒ–æˆåŠŸï¼ˆæ”¯æŒåŠ¨æ€è°ƒæ•´ï¼‰")
            print("  - å°†è‡ªåŠ¨æ£€æµ‹è¯­éŸ³æ´»åŠ¨ï¼ŒæŒ‰å¥å­/åŠå¥å¤„ç†")
            print("  - åˆå§‹é™éŸ³æ£€æµ‹æ—¶é—´: 500ms")
            print("  - åŠ¨æ€è°ƒæ•´èŒƒå›´: 200msï¼ˆå¯†é›†ï¼‰~ 1000msï¼ˆç¨€ç–ï¼‰")
        except ImportError:
            print("âš  æœªå®‰è£… torchï¼Œæ— æ³•ä½¿ç”¨ VAC")
            print("  å°†ä½¿ç”¨æ™®é€šæ¨¡å¼ï¼ˆå›ºå®šæ—¶é—´é—´éš”ï¼‰")
            print("  å¯ä»¥å®‰è£…: pip install torch torchaudio")
            use_vac = False
            # å°è¯•ä½¿ç”¨å¢å¼ºçš„å¤„ç†å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            try:
                from enhanced_asr_processor import EnhancedOnlineASRProcessor
                online = EnhancedOnlineASRProcessor(
                    asr=asr,
                    tokenizer=None,
                    buffer_trimming=("segment", 15),
                    logfile=filtered_logfile,
                    agreement_n=agreement_n,
                    enable_dynamic_buffer=True
                )
                print("âœ“ å¢å¼ºå¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸï¼ˆæ— VACï¼‰")
            except ImportError:
                online = OnlineASRProcessor(asr, tokenizer=None, buffer_trimming=("segment", 15), logfile=filtered_logfile)
                print("âœ“ æ™®é€šå¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸï¼ˆæ— VACï¼‰")
        except Exception as e:
            print(f"âš  VAC åˆå§‹åŒ–å¤±è´¥: {e}")
            print("  å°†ä½¿ç”¨æ™®é€šæ¨¡å¼ï¼ˆå›ºå®šæ—¶é—´é—´éš”ï¼‰")
            use_vac = False
            # å°è¯•ä½¿ç”¨å¢å¼ºçš„å¤„ç†å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            try:
                from enhanced_asr_processor import EnhancedOnlineASRProcessor
                online = EnhancedOnlineASRProcessor(
                    asr=asr,
                    tokenizer=None,
                    buffer_trimming=("segment", 15),
                    logfile=filtered_logfile,
                    agreement_n=agreement_n,
                    enable_dynamic_buffer=True
                )
                print("âœ“ å¢å¼ºå¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸï¼ˆæ— VACï¼Œå›é€€æ¨¡å¼ï¼‰")
            except ImportError:
                online = OnlineASRProcessor(asr, tokenizer=None, buffer_trimming=("segment", 15), logfile=filtered_logfile)
                print("âœ“ æ™®é€šå¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸï¼ˆæ— VACï¼Œå›é€€æ¨¡å¼ï¼‰")
    else:
        # å°è¯•ä½¿ç”¨å¢å¼ºçš„å¤„ç†å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            from enhanced_asr_processor import EnhancedOnlineASRProcessor
            online = EnhancedOnlineASRProcessor(
                asr=asr,
                tokenizer=None,
                buffer_trimming=("segment", 15),
                logfile=sys.stderr,
                agreement_n=2,
                enable_dynamic_buffer=True
            )
            print("âœ“ å¢å¼ºå¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸï¼ˆæ— VACæ¨¡å¼ï¼‰")
        except ImportError:
            online = OnlineASRProcessor(asr, tokenizer=None, buffer_trimming=("segment", 15), logfile=sys.stderr)
            print("âœ“ æ™®é€šå¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸï¼ˆæ— VACæ¨¡å¼ï¼‰")
    
    print()
    print("=" * 60)
    print("å¼€å§‹å½•éŸ³ä¼šè¯")
    print("=" * 60)
    print()
    
    # åˆ—å‡ºè®¾å¤‡å¹¶é€‰æ‹©ï¼ˆåªåœ¨ç¨‹åºå¯åŠ¨æ—¶é€‰æ‹©ä¸€æ¬¡ï¼‰
    print("æ­£åœ¨æ£€æµ‹éŸ³é¢‘è®¾å¤‡...")
    input_devices = list_audio_devices(force_refresh=True)
    
    # é€‰æ‹©è®¾å¤‡
    device_idx = select_device(input_devices)
    if device_idx is None:
        print("æœªé€‰æ‹©è®¾å¤‡ï¼Œé€€å‡ºç¨‹åº")
        return
    
    selected_device = input_devices[device_idx]
    print(f"å·²é€‰æ‹©è®¾å¤‡: {selected_device['name']}")
    print()
    
    # è®¡ç®—è¯»å–å—å¤§å°
    if use_vac:
        read_chunk_size = int(0.04 * SAMPLING_RATE)  # VAC æ¨èï¼š0.04 ç§’ï¼ˆ512 æ ·æœ¬ï¼‰
    elif model_size in ['large-v2', 'large-v3', 'large']:
        read_chunk_size = int(0.5 * SAMPLING_RATE)  # å¤§æ¨¡å‹ï¼šæ¯æ¬¡è¯»å– 0.5 ç§’
    else:
        read_chunk_size = int(0.3 * SAMPLING_RATE)  # ä¸­å°æ¨¡å‹ï¼šæ¯æ¬¡è¯»å– 0.3 ç§’
    
    # æ‰“å¼€éŸ³é¢‘æµï¼ˆåœ¨æ•´ä¸ªç¨‹åºè¿è¡ŒæœŸé—´ä¿æŒæ‰“å¼€ï¼Œé¿å…åå¤å ç”¨/é‡Šæ”¾è®¾å¤‡ï¼‰
    if perf_display:
        perf_display.display_progress("æ­£åœ¨æ‰“å¼€éº¦å…‹é£...")
    else:
        print("æ­£åœ¨æ‰“å¼€éº¦å…‹é£...")
    
    # ä½¿ç”¨éŸ³é¢‘è®¾å¤‡ä¿æŠ¤å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    device_protector = None
    stream = None
    
    if DEVICE_PROTECTOR_AVAILABLE:
        device_config = config_manager.get_device_protector_config() if config_manager else {}
        device_protector = AudioDeviceProtector(
            max_retries=device_config.get('max_retries', 3),
            retry_delay=device_config.get('retry_delay', 1.0),
            check_interval=device_config.get('check_interval', 0.5)
        )
        success, stream, error = device_protector.open_stream(
            device_index=selected_device['index'],
            samplerate=SAMPLING_RATE,
            channels=1,
            blocksize=read_chunk_size,
            dtype='float32'
        )
        if not success:
            if perf_display:
                perf_display.clear()
                perf_display.display_error(
                    "è®¾å¤‡æ‰“å¼€å¤±è´¥",
                    error,
                    "è¯·æ£€æŸ¥éº¦å…‹é£æ˜¯å¦å·²è¿æ¥å¹¶å¯ç”¨ï¼Œæˆ–æ˜¯å¦è¢«å…¶ä»–ç¨‹åºå ç”¨"
                )
            else:
                print(f"âœ— æ— æ³•æ‰“å¼€éŸ³é¢‘æµ: {error}")
                print("æç¤º: è¯·æ£€æŸ¥éº¦å…‹é£æ˜¯å¦å·²è¿æ¥å¹¶å¯ç”¨ï¼Œæˆ–æ˜¯å¦è¢«å…¶ä»–ç¨‹åºå ç”¨")
            return
        
        # è®¾ç½®æ€§èƒ½æ˜¾ç¤ºå™¨çš„è®¾å¤‡ä¿æŠ¤å™¨
        if perf_display:
            perf_display.set_device_protector(device_protector)
            perf_display.clear()
            perf_display.display_success("éº¦å…‹é£å·²å°±ç»ªï¼ˆè®¾å¤‡ä¿æŠ¤å·²å¯ç”¨ï¼‰")
        else:
            print("âœ“ éº¦å…‹é£å·²å°±ç»ªï¼ˆè®¾å¤‡ä¿æŠ¤å·²å¯ç”¨ï¼‰")
        print()
    else:
        # å›é€€åˆ°åŸºç¡€æ¨¡å¼
        try:
            stream = sd.InputStream(
                samplerate=SAMPLING_RATE,
                channels=1,
                dtype='float32',
                blocksize=read_chunk_size,
                device=selected_device['index']
            )
            stream.start()
            if perf_display:
                perf_display.clear()
                perf_display.display_success("éº¦å…‹é£å·²å°±ç»ª")
            else:
                print("âœ“ éº¦å…‹é£å·²å°±ç»ª")
            print()
        except Exception as e:
            if perf_display:
                perf_display.clear()
                perf_display.display_error(
                    "è®¾å¤‡æ‰“å¼€å¤±è´¥",
                    str(e),
                    "è¯·æ£€æŸ¥éº¦å…‹é£æ˜¯å¦å·²è¿æ¥å¹¶å¯ç”¨"
                )
            else:
                print(f"âœ— æ— æ³•æ‰“å¼€éŸ³é¢‘æµ: {e}")
                print("æç¤º: è¯·æ£€æŸ¥éº¦å…‹é£æ˜¯å¦å·²è¿æ¥å¹¶å¯ç”¨")
            return
    
    # ä¸»å¾ªç¯ï¼šå¯ä»¥å¤šæ¬¡å½•éŸ³ä¼šè¯ï¼ˆéŸ³é¢‘æµä¿æŒæ‰“å¼€ï¼‰
    session_count = 0
    try:
        while True:
            session_count += 1
            if session_count > 1:
                print()
                print("=" * 60)
                print(f"å¼€å§‹æ–°çš„å½•éŸ³ä¼šè¯ #{session_count}")
                print("=" * 60)
                print()
                
                # è¯¢é—®æ˜¯å¦è¦æ›´æ”¹è¯­è¨€ï¼ˆå¯ä»¥é‡æ–°åŠ è½½æ¨¡å‹ï¼‰
                print(f"å½“å‰è¯†åˆ«è¯­è¨€: {input_language} ({'è‡ªåŠ¨æ£€æµ‹' if input_language == 'auto' else input_language})")
                try:
                    lang_choice = input("æ˜¯å¦æ›´æ”¹è¯†åˆ«è¯­è¨€ï¼Ÿ(ç›´æ¥å›è½¦ä¿æŒå½“å‰ï¼Œæˆ–è¾“å…¥è¯­è¨€ä»£ç ï¼Œå¦‚ 'zh'/'en'/'auto'): ").strip()
                    
                    if lang_choice:
                        lang_choice = lang_choice.lower()
                        # éªŒè¯è¯­è¨€ä»£ç 
                        if lang_choice in valid_languages:
                            if lang_choice != input_language:
                                # éœ€è¦æ›´æ”¹è¯­è¨€ï¼Œé‡æ–°åŠ è½½æ¨¡å‹
                                print(f"æ­£åœ¨æ›´æ”¹è¯­è¨€ä¸º: {lang_choice} ({'è‡ªåŠ¨æ£€æµ‹' if lang_choice == 'auto' else lang_choice})")
                                print("æ­£åœ¨é‡æ–°åŠ è½½æ¨¡å‹ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ ç§’é’Ÿï¼‰...")
                                
                                # é‡Šæ”¾æ—§æ¨¡å‹ï¼ˆé‡Šæ”¾GPUå†…å­˜ï¼‰
                                try:
                                    del asr
                                    del online
                                    import gc
                                    gc.collect()
                                    if device == "cuda":
                                        import torch
                                        torch.cuda.empty_cache()
                                except:
                                    pass
                                
                                # æ›´æ–°è¯­è¨€
                                input_language = lang_choice
                                
                                # æ ¹æ®æ–°è¯­è¨€é‡æ–°è¯»å–é…ç½®
                                if CONFIG_MANAGER_AVAILABLE and config_manager:
                                    # è·å–è¯­è¨€ç‰¹å®šçš„ ASR ä¼˜åŒ–é…ç½®
                                    asr_opt = config_manager.get_language_specific_config(input_language, "asr_optimization")
                                    vac_chunk_size = asr_opt.get("vac_chunk_size", 0.08)
                                    agreement_n = asr_opt.get("agreement_n", 3)
                                    beam_size = asr_opt.get("beam_size", 5)
                                    temperature = asr_opt.get("temperature", 0.0)
                                    vad_threshold = asr_opt.get("vad_threshold", 0.6)
                                    
                                    # è·å–è¯­è¨€ç‰¹å®šçš„è¯­é€Ÿè‡ªé€‚åº”é…ç½®
                                    speech_rate_config = config_manager.get_language_specific_config(input_language, "speech_rate_adaptive")
                                    vad_initial_silence_ms = speech_rate_config.get("initial_silence_ms", 1000)
                                    vad_min_silence_ms = speech_rate_config.get("min_silence_ms", 500)
                                    vad_max_silence_ms = speech_rate_config.get("max_silence_ms", 1500)
                                    
                                    print(f"âœ“ å·²åŠ è½½è¯­è¨€ç‰¹å®šé…ç½® ({input_language}): agreement_n={agreement_n}, VADé™éŸ³={vad_min_silence_ms}-{vad_max_silence_ms}ms")
                                
                                # é‡æ–°åˆ›å»º ASR å¯¹è±¡
                                if device == "cuda":
                                    try:
                                        transcribe_kwargs = {
                                            'beam_size': beam_size,
                                            'temperature': temperature
                                        }
                                        asr = CustomFasterWhisperASR(
                                            lan=input_language, 
                                            modelsize=model_size, 
                                            cache_dir=model_cache_dir,
                                            device="cuda",
                                            compute_type=compute_type,
                                            device_index=low_level_params['device_index'],
                                            num_workers=low_level_params['num_workers'],
                                            transcribe_kwargs=transcribe_kwargs
                                        )
                                        print("âœ“ æ¨¡å‹é‡æ–°åŠ è½½æˆåŠŸï¼ˆGPU æ¨¡å¼ï¼‰")
                                    except Exception as e:
                                        print(f"âš  GPU é‡æ–°åŠ è½½å¤±è´¥: {e}")
                                        print("  å°è¯•ä½¿ç”¨ CPU æ¨¡å¼...")
                                        device = "cpu"
                                        compute_type = "int8"
                                        low_level_params = optimize_low_level_params(hardware, False, model_size)
                                
                                if asr is None or device == "cpu":
                                    try:
                                        transcribe_kwargs = {
                                            'beam_size': beam_size,
                                            'temperature': temperature
                                        }
                                        asr = CustomFasterWhisperASR(
                                            lan=input_language, 
                                            modelsize=model_size, 
                                            cache_dir=model_cache_dir,
                                            device="cpu",
                                            compute_type="int8",
                                            num_workers=low_level_params['num_workers'],
                                            cpu_threads=low_level_params.get('cpu_threads'),
                                            transcribe_kwargs=transcribe_kwargs
                                        )
                                        print("âœ“ æ¨¡å‹é‡æ–°åŠ è½½æˆåŠŸï¼ˆCPU æ¨¡å¼ï¼‰")
                                    except Exception as e:
                                        print(f"âœ— æ¨¡å‹é‡æ–°åŠ è½½å¤±è´¥: {e}")
                                        print("æç¤º: å°†ä½¿ç”¨ä¹‹å‰çš„æ¨¡å‹å’Œè¯­è¨€è®¾ç½®")
                                        # æ¢å¤ä¹‹å‰çš„è¯­è¨€
                                        input_language = lang_choice  # å·²ç»æ›´æ”¹äº†ï¼Œä¿æŒæ–°è¯­è¨€
                                
                                # é‡æ–°åˆ›å»º online å¤„ç†å™¨
                                if use_vac:
                                    # ç¡®ä¿ filtered_logfile å­˜åœ¨
                                    if 'filtered_logfile' not in locals():
                                        class FilteredLogFile:
                                            def __init__(self, original_file):
                                                self.original_file = original_file
                                            def write(self, text):
                                                pass
                                            def flush(self):
                                                self.original_file.flush()
                                        filtered_logfile = FilteredLogFile(sys.stderr)
                                    
                                    try:
                                        from enhanced_asr_processor import EnhancedVACOnlineASRProcessor
                                        online = EnhancedVACOnlineASRProcessor(
                                            online_chunk_size=vac_chunk_size,
                                            asr=asr,
                                            tokenizer=None,
                                            logfile=filtered_logfile,
                                            buffer_trimming=("segment", 15),
                                            initial_silence_ms=vad_initial_silence_ms,
                                            min_silence_ms=vad_min_silence_ms,
                                            max_silence_ms=vad_max_silence_ms,
                                            agreement_n=agreement_n,
                                            enable_dynamic_buffer=True,
                                            vad_threshold=vad_threshold
                                        )
                                        print("âœ“ å¢å¼º VAC å¤„ç†å™¨é‡æ–°åˆå§‹åŒ–æˆåŠŸ")
                                    except ImportError:
                                        online = DynamicVACOnlineASRProcessor(
                                            vac_chunk_size,
                                            asr,
                                            tokenizer=None,
                                            logfile=filtered_logfile,
                                            buffer_trimming=("segment", 15),
                                            initial_silence_ms=vad_initial_silence_ms,
                                            min_silence_ms=vad_min_silence_ms,
                                            max_silence_ms=vad_max_silence_ms,
                                            vad_threshold=vad_threshold
                                        )
                                        print("âœ“ VAC å¤„ç†å™¨é‡æ–°åˆå§‹åŒ–æˆåŠŸ")
                                else:
                                    try:
                                        from enhanced_asr_processor import EnhancedOnlineASRProcessor
                                        online = EnhancedOnlineASRProcessor(
                                            asr=asr,
                                            tokenizer=None,
                                            buffer_trimming=("segment", 15),
                                            logfile=sys.stderr,
                                            agreement_n=2,
                                            enable_dynamic_buffer=True
                                        )
                                        print("âœ“ å¢å¼ºå¤„ç†å™¨é‡æ–°åˆå§‹åŒ–æˆåŠŸ")
                                    except ImportError:
                                        online = OnlineASRProcessor(asr, tokenizer=None, buffer_trimming=("segment", 15), logfile=sys.stderr)
                                        print("âœ“ æ™®é€šå¤„ç†å™¨é‡æ–°åˆå§‹åŒ–æˆåŠŸ")
                                
                                print(f"âœ“ è¯­è¨€å·²æ›´æ”¹ä¸º: {input_language} ({'è‡ªåŠ¨æ£€æµ‹' if input_language == 'auto' else input_language})")
                            else:
                                print(f"è¯­è¨€æœªæ”¹å˜ï¼Œä»ä¸º: {input_language}")
                        else:
                            print(f"âš  æœªè¯†åˆ«çš„è¯­è¨€ä»£ç  '{lang_choice}'ï¼Œä¿æŒå½“å‰è¯­è¨€: {input_language}")
                    else:
                        print(f"ä¿æŒå½“å‰è¯­è¨€: {input_language}")
                except KeyboardInterrupt:
                    print("\nä¿æŒå½“å‰è¯­è¨€")
                print()
            
            print("æŒ‰ Ctrl+C åœæ­¢å½“å‰ä¼šè¯")
            print("-" * 60)
            print()
            
            # æ‰§è¡Œå½•éŸ³ä¼šè¯
            # æ ¹æ®æ¨¡å‹å¤§å°è°ƒæ•´å¤„ç†é—´éš”
            if model_size in ['large-v2', 'large-v3', 'large']:
                actual_chunk_duration = max(CHUNK_DURATION, 2.0)  # å¤§æ¨¡å‹è‡³å°‘ 2 ç§’
            else:
                actual_chunk_duration = CHUNK_DURATION
            
            success = record_session(
                online, 
                stream,  # ä¼ å…¥å·²æ‰“å¼€çš„éŸ³é¢‘æµ
                device_idx=device_idx,
                model_size=model_size,
                chunk_duration=actual_chunk_duration,
                use_vac=use_vac,
                config_manager=config_manager,  # ä¼ é€’é…ç½®ç®¡ç†å™¨
                perf_display=perf_display,  # ä¼ é€’æ€§èƒ½æ˜¾ç¤ºå™¨
                device_protector=device_protector,  # ä¼ é€’è®¾å¤‡ä¿æŠ¤å™¨
                input_language=input_language,  # ä¼ é€’å½“å‰è¯­è¨€
                translation_manager=translation_manager  # ä¼ é€’ç¿»è¯‘ç®¡ç†å™¨
            )
            
            if not success:
                break
            
            # è¯¢é—®æ˜¯å¦ç»§ç»­
            print()
            try:
                choice = input("æ˜¯å¦ç»§ç»­å½•éŸ³ï¼Ÿ(y/nï¼Œç›´æ¥å›è½¦ç»§ç»­): ").strip().lower()
                if choice in ['n', 'no', 'é€€å‡º', 'exit', 'quit']:
                    print("é€€å‡ºç¨‹åº")
                    break
                # å…¶ä»–æƒ…å†µï¼ˆåŒ…æ‹¬ç›´æ¥å›è½¦ï¼‰éƒ½ç»§ç»­
            except KeyboardInterrupt:
                print("\né€€å‡ºç¨‹åº")
                break
    finally:
        # ç¨‹åºé€€å‡ºæ—¶å…³é—­éŸ³é¢‘æµ
        print("\næ­£åœ¨å…³é—­éŸ³é¢‘æµ...")
        try:
            if device_protector is not None:
                device_protector.close()
            else:
                if stream is not None:
                    stream.stop()
                    stream.close()
            print("âœ“ éŸ³é¢‘æµå·²å…³é—­")
        except:
            pass
        
        # åœæ­¢ç¿»è¯‘ç®¡ç†å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if translation_manager is not None:
            try:
                translation_manager.stop()
                stats = translation_manager.get_stats()
                print(f"\nç¿»è¯‘ç»Ÿè®¡: æ·»åŠ ={stats['total_added']}, ç¿»è¯‘={stats['total_translated']}, å¤±è´¥={stats['total_failed']}, é‡è¯•={stats['total_retried']}")
            except:
                pass

if __name__ == "__main__":
    main()

